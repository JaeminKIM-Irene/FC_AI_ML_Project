{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHdZJJ3vf/4FSD1do/0E0O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaeminKIM-Irene/FC_AI_ML_Project/blob/main/ML_Project_LightGBM_PCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbtR1wYDzced",
        "outputId": "b1b71096-cece-4709-d5c8-ad4e235bfc1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.0.0)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.11.3)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.12.0)\n",
            "Requirement already satisfied: cmaes>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (0.10.0)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.7.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.21)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n"
          ]
        }
      ],
      "source": [
        "# 설치에 필요한 라이브러리들이 있다면 모두 적어둡니다. anaconda에 기본적으로 설치되지 않은 라이브러리들을 적어두세요.\n",
        "!pip install lightgbm optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import optuna\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from functools import partial\n",
        "\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "FZXOedhNz3CE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# google drive mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3XtSOYZ0Doh",
        "outputId": "65a9f4d6-908f-4ebd-e225-a261b002448b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read data\n",
        "result_list = []\n",
        "base_url = '/content/drive/MyDrive/Colab Notebooks/data/playground-series-s3e23/'\n",
        "train = pd.read_csv(base_url+'train.csv', index_col='id')\n",
        "test = pd.read_csv(base_url+'test.csv', index_col='id')\n",
        "submission = pd.read_csv(base_url+'sample_submission.csv', index_col='id')\n",
        "\n",
        "with pd.option_context('display.min_rows', 6) :\n",
        "  display(train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "hH_h_uby0GGs",
        "outputId": "1c5af966-5317-4288-c1d5-762913fd9547"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          loc  v(g)  ev(g)  iv(g)      n        v     l      d      i  \\\n",
              "id                                                                      \n",
              "0        22.0   3.0    1.0    2.0   60.0   278.63  0.06  19.56  14.25   \n",
              "1        14.0   2.0    1.0    2.0   32.0   151.27  0.14   7.00  21.11   \n",
              "2        11.0   2.0    1.0    2.0   45.0   197.65  0.11   8.05  22.76   \n",
              "...       ...   ...    ...    ...    ...      ...   ...    ...    ...   \n",
              "101760   26.0   1.0    1.0    1.0   83.0   360.17  0.04  22.75  12.56   \n",
              "101761   10.0   2.0    1.0    2.0   43.0   191.76  0.15   6.46  29.53   \n",
              "101762  136.0  18.0   18.0    1.0  296.0  1704.57  0.02  44.82  44.08   \n",
              "\n",
              "               e  ...  lOCode  lOComment  lOBlank  locCodeAndComment  uniq_Op  \\\n",
              "id                ...                                                           \n",
              "0        5448.79  ...      17          1        1                  0     16.0   \n",
              "1         936.71  ...      11          0        1                  0     11.0   \n",
              "2        1754.01  ...       8          0        1                  0     12.0   \n",
              "...          ...  ...     ...        ...      ...                ...      ...   \n",
              "101760   5893.69  ...      20          0        4                  0     10.0   \n",
              "101761   1534.04  ...       7          0        1                  0     11.0   \n",
              "101762  77011.02  ...     102          1       11                  0     22.0   \n",
              "\n",
              "        uniq_Opnd  total_Op  total_Opnd  branchCount  defects  \n",
              "id                                                             \n",
              "0             9.0      38.0        22.0          5.0    False  \n",
              "1            11.0      18.0        14.0          3.0    False  \n",
              "2            11.0      28.0        17.0          3.0    False  \n",
              "...           ...       ...         ...          ...      ...  \n",
              "101760        8.0      51.0        28.0          1.0    False  \n",
              "101761       14.0      24.0        19.0          3.0    False  \n",
              "101762       31.0     162.0       135.0         35.0    False  \n",
              "\n",
              "[101763 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-870c899e-a017-466a-aa53-e0daa02463df\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loc</th>\n",
              "      <th>v(g)</th>\n",
              "      <th>ev(g)</th>\n",
              "      <th>iv(g)</th>\n",
              "      <th>n</th>\n",
              "      <th>v</th>\n",
              "      <th>l</th>\n",
              "      <th>d</th>\n",
              "      <th>i</th>\n",
              "      <th>e</th>\n",
              "      <th>...</th>\n",
              "      <th>lOCode</th>\n",
              "      <th>lOComment</th>\n",
              "      <th>lOBlank</th>\n",
              "      <th>locCodeAndComment</th>\n",
              "      <th>uniq_Op</th>\n",
              "      <th>uniq_Opnd</th>\n",
              "      <th>total_Op</th>\n",
              "      <th>total_Opnd</th>\n",
              "      <th>branchCount</th>\n",
              "      <th>defects</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>278.63</td>\n",
              "      <td>0.06</td>\n",
              "      <td>19.56</td>\n",
              "      <td>14.25</td>\n",
              "      <td>5448.79</td>\n",
              "      <td>...</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>151.27</td>\n",
              "      <td>0.14</td>\n",
              "      <td>7.00</td>\n",
              "      <td>21.11</td>\n",
              "      <td>936.71</td>\n",
              "      <td>...</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>197.65</td>\n",
              "      <td>0.11</td>\n",
              "      <td>8.05</td>\n",
              "      <td>22.76</td>\n",
              "      <td>1754.01</td>\n",
              "      <td>...</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101760</th>\n",
              "      <td>26.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>360.17</td>\n",
              "      <td>0.04</td>\n",
              "      <td>22.75</td>\n",
              "      <td>12.56</td>\n",
              "      <td>5893.69</td>\n",
              "      <td>...</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101761</th>\n",
              "      <td>10.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>191.76</td>\n",
              "      <td>0.15</td>\n",
              "      <td>6.46</td>\n",
              "      <td>29.53</td>\n",
              "      <td>1534.04</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101762</th>\n",
              "      <td>136.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>1704.57</td>\n",
              "      <td>0.02</td>\n",
              "      <td>44.82</td>\n",
              "      <td>44.08</td>\n",
              "      <td>77011.02</td>\n",
              "      <td>...</td>\n",
              "      <td>102</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>101763 rows × 22 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-870c899e-a017-466a-aa53-e0daa02463df')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-870c899e-a017-466a-aa53-e0daa02463df button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-870c899e-a017-466a-aa53-e0daa02463df');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c6de6c90-41e0-447e-9909-ee59b9a1b006\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c6de6c90-41e0-447e-9909-ee59b9a1b006')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c6de6c90-41e0-447e-9909-ee59b9a1b006 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = train.drop(columns=['defects'])\n",
        "y = train.defects"
      ],
      "metadata": {
        "id": "ZmW-b6Ux2zzm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA Flag\n",
        "feature_reducing = True"
      ],
      "metadata": {
        "id": "mIdKOlAt7vP-"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA\n",
        "if feature_reducing :\n",
        "  from sklearn.decomposition import PCA\n",
        "\n",
        "  pca = PCA(n_components=0.95,\n",
        "            whiten=True,\n",
        "            random_state=61)\n",
        "  pca.fit(X)\n",
        "  pca_df = pd.DataFrame(data=pca.transform(X))\n",
        "  display(pca_df)"
      ],
      "metadata": {
        "id": "KsXgKK5A0MZf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "526edf22-bbd6-436b-a857-b2d70d1a8210"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "               0\n",
              "0      -0.080883\n",
              "1      -0.104576\n",
              "2      -0.100283\n",
              "3      -0.107008\n",
              "4      -0.107576\n",
              "...          ...\n",
              "101758 -0.105233\n",
              "101759 -0.050322\n",
              "101760 -0.078545\n",
              "101761 -0.101438\n",
              "101762  0.294876\n",
              "\n",
              "[101763 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c214d68b-bf0b-4998-8ade-6c957df857dc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.080883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.104576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.100283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.107008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.107576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101758</th>\n",
              "      <td>-0.105233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101759</th>\n",
              "      <td>-0.050322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101760</th>\n",
              "      <td>-0.078545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101761</th>\n",
              "      <td>-0.101438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101762</th>\n",
              "      <td>0.294876</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>101763 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c214d68b-bf0b-4998-8ade-6c957df857dc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c214d68b-bf0b-4998-8ade-6c957df857dc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c214d68b-bf0b-4998-8ade-6c957df857dc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-70376f97-4c19-4365-b133-3412fcf4526d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-70376f97-4c19-4365-b133-3412fcf4526d')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-70376f97-4c19-4365-b133-3412fcf4526d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scree_plot(pca):\n",
        "    num_components = len(pca.explained_variance_ratio_)\n",
        "    ind = np.arange(num_components)\n",
        "    vals = pca.explained_variance_ratio_\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    ax = plt.subplot(111)\n",
        "    cumvals = np.cumsum(vals)\n",
        "    ax.bar(ind, vals)\n",
        "    ax.plot(ind, cumvals)\n",
        "    for i in range(num_components):\n",
        "        ax.annotate(r\"%s%%\" % ((str(round(vals[i]*100,1))[:3])), (ind[i]+0.2, vals[i]),\n",
        "                    va=\"bottom\",\n",
        "                    ha=\"center\",\n",
        "                    fontsize=8)\n",
        "\n",
        "    ax.xaxis.set_tick_params(width=0)\n",
        "    ax.yaxis.set_tick_params(width=1, length=6)\n",
        "\n",
        "    ax.set_xlabel(\"Principal Component\")\n",
        "    ax.set_ylabel(\"Variance Explained (%)\")\n",
        "    plt.title('Explained Variance Per Principal Component')\n",
        "scree_plot(pca)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "bMKi_ZYY8VVs",
        "outputId": "393182a8-d0b0-4c92-ea56-d6dde739a31f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data split for baseline model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(pca_df, y, test_size=0.05, random_state=61)"
      ],
      "metadata": {
        "id": "cPE2SWjs07bc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTRvtY9I1sHX",
        "outputId": "21ee004c-cdce-40f9-a9dc-99c9f0747709"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(96674, 1) (96674,) (5089, 1) (5089,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline Model"
      ],
      "metadata": {
        "id": "GavXEb7M30MX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data split for baseline model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = train.drop(columns=['defects'])\n",
        "y = train.defects\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.05, random_state=61)"
      ],
      "metadata": {
        "id": "VAzYm2VdTHpM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LGBMClassifier()\n",
        "\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "U_l8xKCz1x13",
        "outputId": "2232bdab-4616-404f-82b8-fcbfd380d848"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 21922, number of negative: 74752\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001350 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 255\n",
            "[LightGBM] [Info] Number of data points in the train set: 96674, number of used features: 1\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226762 -> initscore=-1.226685\n",
            "[LightGBM] [Info] Start training from score -1.226685\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('======Prediction======')\n",
        "pred_train = model.predict(X_train)\n",
        "pred_val = model.predict(X_val)\n",
        "\n",
        "train_score = roc_auc_score(y_train, pred_train)\n",
        "val_score = roc_auc_score(y_val, pred_val)\n",
        "\n",
        "print(\"Train Score : %.4f\" % train_score)\n",
        "print(\"Test Score : %.4f\" % val_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVWaqqa92nDc",
        "outputId": "1316674a-914f-4dd7-b66e-b974709f6ae6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======Prediction======\n",
            "Train Score : 0.6488\n",
            "Test Score : 0.6315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "model = Pipeline([('scale', StandardScaler()), ('reduce_dims', PCA(n_components=0.90, random_state=61)), ('clf', LGBMClassifier())])\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "pred_train = model.predict(X_train)\n",
        "pred_val = model.predict(X_val)\n",
        "\n",
        "train_score = roc_auc_score(y_train, pred_train)\n",
        "val_score = roc_auc_score(y_val, pred_val)\n",
        "\n",
        "print(\"Train Score : %.4f\" % train_score)\n",
        "print(\"Test Score : %.4f\" % val_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gu1IDVXSnmm",
        "outputId": "757890ba-c518-4f71-df6c-938cf2a27a30"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 21922, number of negative: 74752\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027472 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 96674, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226762 -> initscore=-1.226685\n",
            "[LightGBM] [Info] Start training from score -1.226685\n",
            "Train Score : 0.6730\n",
            "Test Score : 0.6581\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optuna"
      ],
      "metadata": {
        "id": "mJUBp3PG32cY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def optimizer(trial, X, y, K) :\n",
        "  #num_leaves = trial.suggest_categorical('num_leaves', [64, 128, 256, 512])\n",
        "  num_leaves=64\n",
        "  max_depth = trial.suggest_int('max_depth', 10, 25)\n",
        "  #learning_rate = trial.suggest_float('learning_rate', 0.001, 0.3)\n",
        "  learning_rate=0.030278064653420228\n",
        "  min_child_samples = trial.suggest_int('min_child_samples', 1, 100)\n",
        "  colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 0.8)\n",
        "\n",
        "  model = Pipeline([\n",
        "      ('scale', StandardScaler()),\n",
        "      ('reduce_dims', PCA(n_components=0.90, random_state=61)),\n",
        "      ('clf', LGBMClassifier(num_leaves=num_leaves,\n",
        "                            max_depth=max_depth,\n",
        "                            learning_rate=learning_rate,\n",
        "                            min_child_samples=min_child_samples,\n",
        "                            colsample_bytree=colsample_bytree,\n",
        "                            random_state=61))])\n",
        "\n",
        "  folds = StratifiedKFold(shuffle=True, random_state=61)\n",
        "  oof = np.full(len(train), np.nan)\n",
        "  auc_list = []\n",
        "\n",
        "  for train_idx, val_idx in folds.split(X, y) :\n",
        "    X_train = X.iloc[train_idx, :]\n",
        "    y_train = y.iloc[train_idx]\n",
        "\n",
        "    X_val = X.iloc[val_idx, :]\n",
        "    y_val = y.iloc[val_idx]\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    try :\n",
        "      y_val_pred = model.predict_proba(X_val)[:, 1]\n",
        "    except :\n",
        "      y_val_pred = model.decision_function(X_val)\n",
        "    oof[val_idx] = y_val_pred\n",
        "    auc = roc_auc_score(y_val, y_val_pred)\n",
        "    auc_list.append(auc)\n",
        "\n",
        "  return np.mean(auc_list)"
      ],
      "metadata": {
        "id": "mH53aZYP3dJ3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K = 5\n",
        "opt_func = partial(optimizer, X=X_train, y=y_train, K=K)\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(opt_func, n_trials=50)"
      ],
      "metadata": {
        "id": "AkioR4Ms58pf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f85b1ac-e2cc-40c2-a28d-61853ed66e1e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:39:12,996] A new study created in memory with name: no-name-8ce8ef67-81f7-4cea-aedc-01ed5bc5c42e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009008 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005649 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005911 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005731 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010634 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:39:21,073] Trial 0 finished with value: 0.7844967102858711 and parameters: {'max_depth': 19, 'min_child_samples': 91, 'colsample_bytree': 0.6792116773619657}. Best is trial 0 with value: 0.7844967102858711.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005906 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009951 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041840 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005863 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005511 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:39:32,407] Trial 1 finished with value: 0.78438794252321 and parameters: {'max_depth': 15, 'min_child_samples': 77, 'colsample_bytree': 0.5938935412837442}. Best is trial 0 with value: 0.7844967102858711.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005714 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005665 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006105 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005596 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008615 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:39:39,136] Trial 2 finished with value: 0.784351930962213 and parameters: {'max_depth': 21, 'min_child_samples': 48, 'colsample_bytree': 0.6023982086444924}. Best is trial 0 with value: 0.7844967102858711.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005216 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008020 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008064 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004870 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005349 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:39:46,966] Trial 3 finished with value: 0.7826176083163487 and parameters: {'max_depth': 22, 'min_child_samples': 70, 'colsample_bytree': 0.5379214914809876}. Best is trial 0 with value: 0.7844967102858711.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006123 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005774 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006003 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005773 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005785 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:39:54,015] Trial 4 finished with value: 0.7842638691197299 and parameters: {'max_depth': 15, 'min_child_samples': 87, 'colsample_bytree': 0.7839130814253207}. Best is trial 0 with value: 0.7844967102858711.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005785 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009252 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009193 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005837 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005769 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:40:02,176] Trial 5 finished with value: 0.7845170833604682 and parameters: {'max_depth': 20, 'min_child_samples': 93, 'colsample_bytree': 0.623458582039218}. Best is trial 5 with value: 0.7845170833604682.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005803 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005636 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005953 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005935 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005711 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:40:09,147] Trial 6 finished with value: 0.784354502876585 and parameters: {'max_depth': 24, 'min_child_samples': 67, 'colsample_bytree': 0.7880929600987323}. Best is trial 5 with value: 0.7845170833604682.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010149 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009173 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009779 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005487 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005927 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:40:17,257] Trial 7 finished with value: 0.7844286246619088 and parameters: {'max_depth': 24, 'min_child_samples': 66, 'colsample_bytree': 0.6668216489275065}. Best is trial 5 with value: 0.7845170833604682.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005629 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005690 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005412 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009892 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005986 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:40:23,979] Trial 8 finished with value: 0.7845251994420086 and parameters: {'max_depth': 16, 'min_child_samples': 91, 'colsample_bytree': 0.5948781817782184}. Best is trial 8 with value: 0.7845251994420086.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009403 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009454 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009875 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005692 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005772 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:40:32,108] Trial 9 finished with value: 0.7842219248216734 and parameters: {'max_depth': 18, 'min_child_samples': 54, 'colsample_bytree': 0.6032344425675735}. Best is trial 8 with value: 0.7845251994420086.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005158 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005210 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004972 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004986 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005290 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:40:38,363] Trial 10 finished with value: 0.7823721831172868 and parameters: {'max_depth': 10, 'min_child_samples': 6, 'colsample_bytree': 0.5051128444703711}. Best is trial 8 with value: 0.7845251994420086.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005713 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008986 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009866 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005428 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005952 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:40:46,538] Trial 11 finished with value: 0.7843986756560334 and parameters: {'max_depth': 14, 'min_child_samples': 100, 'colsample_bytree': 0.6576680504248356}. Best is trial 8 with value: 0.7845251994420086.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009642 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005433 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005542 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005475 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005446 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:40:53,610] Trial 12 finished with value: 0.7842840000566765 and parameters: {'max_depth': 12, 'min_child_samples': 26, 'colsample_bytree': 0.5644563529881645}. Best is trial 8 with value: 0.7845251994420086.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009657 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009019 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010242 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006008 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005509 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:41:01,853] Trial 13 finished with value: 0.7843583859493326 and parameters: {'max_depth': 17, 'min_child_samples': 99, 'colsample_bytree': 0.6104702961708006}. Best is trial 8 with value: 0.7845251994420086.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006121 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005694 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005975 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005812 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005752 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:41:08,872] Trial 14 finished with value: 0.784466759490037 and parameters: {'max_depth': 20, 'min_child_samples': 47, 'colsample_bytree': 0.7063095251493015}. Best is trial 8 with value: 0.7845251994420086.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008664 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009158 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009817 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005637 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005562 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:41:16,995] Trial 15 finished with value: 0.784382416263346 and parameters: {'max_depth': 17, 'min_child_samples': 80, 'colsample_bytree': 0.6278065457255315}. Best is trial 8 with value: 0.7845251994420086.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005459 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005949 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005513 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005630 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006550 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:41:23,732] Trial 16 finished with value: 0.7841258284476098 and parameters: {'max_depth': 22, 'min_child_samples': 30, 'colsample_bytree': 0.5694177050322422}. Best is trial 8 with value: 0.7845251994420086.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008947 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008975 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010057 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005552 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005919 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:41:31,804] Trial 17 finished with value: 0.7843837208842986 and parameters: {'max_depth': 13, 'min_child_samples': 85, 'colsample_bytree': 0.6364634455005121}. Best is trial 8 with value: 0.7845251994420086.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005576 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005029 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005306 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005476 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005288 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:41:38,285] Trial 18 finished with value: 0.7825850430313762 and parameters: {'max_depth': 16, 'min_child_samples': 57, 'colsample_bytree': 0.5338511952616457}. Best is trial 8 with value: 0.7845251994420086.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009273 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009376 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009341 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006224 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005852 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:41:46,742] Trial 19 finished with value: 0.7842498840521659 and parameters: {'max_depth': 19, 'min_child_samples': 93, 'colsample_bytree': 0.7068603197324426}. Best is trial 8 with value: 0.7845251994420086.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005707 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005682 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005996 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005912 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005989 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:41:53,570] Trial 20 finished with value: 0.7843830873311328 and parameters: {'max_depth': 25, 'min_child_samples': 76, 'colsample_bytree': 0.6358922605840032}. Best is trial 8 with value: 0.7845251994420086.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009663 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010827 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014395 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006340 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005829 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:42:02,311] Trial 21 finished with value: 0.7844950764101972 and parameters: {'max_depth': 19, 'min_child_samples': 90, 'colsample_bytree': 0.6632659844584429}. Best is trial 8 with value: 0.7845251994420086.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005723 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006125 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006320 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009549 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010675 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:42:10,330] Trial 22 finished with value: 0.7842498840521659 and parameters: {'max_depth': 19, 'min_child_samples': 93, 'colsample_bytree': 0.6889302826538464}. Best is trial 8 with value: 0.7845251994420086.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009335 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009028 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005568 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005917 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006100 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:42:17,856] Trial 23 finished with value: 0.7844827178030863 and parameters: {'max_depth': 21, 'min_child_samples': 100, 'colsample_bytree': 0.5762301271654711}. Best is trial 8 with value: 0.7845251994420086.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005844 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005796 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006437 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005661 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009512 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:42:25,378] Trial 24 finished with value: 0.7843833262279425 and parameters: {'max_depth': 18, 'min_child_samples': 84, 'colsample_bytree': 0.6299052327333431}. Best is trial 8 with value: 0.7845251994420086.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009536 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005846 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005610 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005556 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005411 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:42:32,895] Trial 25 finished with value: 0.7843889941901155 and parameters: {'max_depth': 16, 'min_child_samples': 75, 'colsample_bytree': 0.6734629936439019}. Best is trial 8 with value: 0.7845251994420086.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005936 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005771 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005965 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005657 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004116 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:42:41,017] Trial 26 finished with value: 0.784638184861284 and parameters: {'max_depth': 20, 'min_child_samples': 61, 'colsample_bytree': 0.7234385199718164}. Best is trial 26 with value: 0.784638184861284.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009109 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005921 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005902 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006094 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005946 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:42:48,346] Trial 27 finished with value: 0.7845831363119883 and parameters: {'max_depth': 22, 'min_child_samples': 38, 'colsample_bytree': 0.7175390408053408}. Best is trial 26 with value: 0.784638184861284.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005975 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005929 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005981 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009861 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009002 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:42:56,284] Trial 28 finished with value: 0.7842259027970224 and parameters: {'max_depth': 23, 'min_child_samples': 27, 'colsample_bytree': 0.7403079448310138}. Best is trial 26 with value: 0.784638184861284.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009020 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005964 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007360 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006224 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006021 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:43:03,497] Trial 29 finished with value: 0.7844479300456927 and parameters: {'max_depth': 21, 'min_child_samples': 38, 'colsample_bytree': 0.7545727631254946}. Best is trial 26 with value: 0.784638184861284.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006026 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005684 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005645 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008768 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009149 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:43:11,578] Trial 30 finished with value: 0.7842462000867005 and parameters: {'max_depth': 23, 'min_child_samples': 14, 'colsample_bytree': 0.7298217401967207}. Best is trial 26 with value: 0.784638184861284.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009872 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010121 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006052 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005923 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005522 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:43:18,665] Trial 31 finished with value: 0.7843160340333355 and parameters: {'max_depth': 20, 'min_child_samples': 39, 'colsample_bytree': 0.6974478832264239}. Best is trial 26 with value: 0.784638184861284.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005815 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006250 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005992 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009044 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009139 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:43:26,675] Trial 32 finished with value: 0.7842906610325523 and parameters: {'max_depth': 20, 'min_child_samples': 61, 'colsample_bytree': 0.6807382977899628}. Best is trial 26 with value: 0.784638184861284.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005626 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006256 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006026 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005587 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006019 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:43:33,419] Trial 33 finished with value: 0.7843894498161281 and parameters: {'max_depth': 22, 'min_child_samples': 44, 'colsample_bytree': 0.6495569121651052}. Best is trial 26 with value: 0.784638184861284.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005561 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005607 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005890 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009792 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009250 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:43:41,832] Trial 34 finished with value: 0.7843420111007194 and parameters: {'max_depth': 21, 'min_child_samples': 34, 'colsample_bytree': 0.7235758682681375}. Best is trial 26 with value: 0.784638184861284.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005851 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005885 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005738 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005760 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005877 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:43:48,545] Trial 35 finished with value: 0.7842695741185215 and parameters: {'max_depth': 16, 'min_child_samples': 52, 'colsample_bytree': 0.6162322813476587}. Best is trial 26 with value: 0.784638184861284.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006013 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005793 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006031 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008956 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009085 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:43:56,694] Trial 36 finished with value: 0.7843521141633825 and parameters: {'max_depth': 18, 'min_child_samples': 72, 'colsample_bytree': 0.5906221544845068}. Best is trial 26 with value: 0.784638184861284.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005925 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005808 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006122 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006143 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005869 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:44:03,693] Trial 37 finished with value: 0.7843729378728961 and parameters: {'max_depth': 23, 'min_child_samples': 62, 'colsample_bytree': 0.7722507796602155}. Best is trial 26 with value: 0.784638184861284.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005505 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005952 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009151 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008916 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009186 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:44:11,844] Trial 38 finished with value: 0.7844132859553637 and parameters: {'max_depth': 15, 'min_child_samples': 81, 'colsample_bytree': 0.6524761781315227}. Best is trial 26 with value: 0.784638184861284.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006078 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005924 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006209 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006091 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005883 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:44:18,407] Trial 39 finished with value: 0.7842150017210304 and parameters: {'max_depth': 20, 'min_child_samples': 21, 'colsample_bytree': 0.6868333990370676}. Best is trial 26 with value: 0.784638184861284.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006097 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005945 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011608 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009168 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009194 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:44:26,758] Trial 40 finished with value: 0.7843315651495312 and parameters: {'max_depth': 25, 'min_child_samples': 68, 'colsample_bytree': 0.7657748029627287}. Best is trial 26 with value: 0.784638184861284.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006212 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005466 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006228 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005454 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007280 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:44:33,788] Trial 41 finished with value: 0.7845241947895841 and parameters: {'max_depth': 22, 'min_child_samples': 94, 'colsample_bytree': 0.7983923803409375}. Best is trial 26 with value: 0.784638184861284.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006110 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005885 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009857 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010154 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005702 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:44:42,299] Trial 42 finished with value: 0.784340297559789 and parameters: {'max_depth': 22, 'min_child_samples': 95, 'colsample_bytree': 0.787912182922414}. Best is trial 26 with value: 0.784638184861284.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009477 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006254 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005717 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005761 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005871 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:44:49,323] Trial 43 finished with value: 0.7842287903519478 and parameters: {'max_depth': 24, 'min_child_samples': 88, 'colsample_bytree': 0.7962598096321964}. Best is trial 26 with value: 0.784638184861284.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006086 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009536 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009718 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009123 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005729 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:44:57,769] Trial 44 finished with value: 0.7844605473656118 and parameters: {'max_depth': 22, 'min_child_samples': 96, 'colsample_bytree': 0.7501197064943826}. Best is trial 26 with value: 0.784638184861284.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005891 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005732 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005845 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006067 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005937 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:45:04,786] Trial 45 finished with value: 0.784275525000659 and parameters: {'max_depth': 21, 'min_child_samples': 80, 'colsample_bytree': 0.7770071164836503}. Best is trial 26 with value: 0.784638184861284.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005606 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009796 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008893 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005980 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005978 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:45:13,179] Trial 46 finished with value: 0.7843280899365705 and parameters: {'max_depth': 19, 'min_child_samples': 89, 'colsample_bytree': 0.7214850220971185}. Best is trial 26 with value: 0.784638184861284.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005693 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005988 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005826 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005623 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007805 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:45:20,153] Trial 47 finished with value: 0.7844314197838 and parameters: {'max_depth': 14, 'min_child_samples': 45, 'colsample_bytree': 0.7980805157601072}. Best is trial 26 with value: 0.784638184861284.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005967 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009759 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009789 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005719 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005706 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:45:28,574] Trial 48 finished with value: 0.7843649265821411 and parameters: {'max_depth': 17, 'min_child_samples': 84, 'colsample_bytree': 0.762884221607005}. Best is trial 26 with value: 0.784638184861284.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005986 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59801\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005709 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226768 -> initscore=-1.226652\n",
            "[LightGBM] [Info] Start training from score -1.226652\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006667 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17537, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005764 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77339, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226755 -> initscore=-1.226726\n",
            "[LightGBM] [Info] Start training from score -1.226726\n",
            "[LightGBM] [Info] Number of positive: 17538, number of negative: 59802\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005852 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2040\n",
            "[LightGBM] [Info] Number of data points in the train set: 77340, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226765 -> initscore=-1.226669\n",
            "[LightGBM] [Info] Start training from score -1.226669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-10-16 07:45:35,434] Trial 49 finished with value: 0.7842193171527747 and parameters: {'max_depth': 23, 'min_child_samples': 19, 'colsample_bytree': 0.7809591326296303}. Best is trial 26 with value: 0.784638184861284.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# boosting type = dart"
      ],
      "metadata": {
        "id": "boXhKibtZ_MU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study.trials_dataframe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DuLq8ZGq8s8p",
        "outputId": "6d5ce297-83b9-4235-ae9b-3fa18b682c99"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    number     value             datetime_start          datetime_complete  \\\n",
              "0        0  0.770301 2023-10-16 05:17:35.387827 2023-10-16 05:17:40.150510   \n",
              "1        1  0.770312 2023-10-16 05:17:40.152280 2023-10-16 05:17:46.009781   \n",
              "2        2  0.770177 2023-10-16 05:17:46.011590 2023-10-16 05:17:52.621830   \n",
              "3        3  0.770334 2023-10-16 05:17:52.623603 2023-10-16 05:17:57.071666   \n",
              "4        4  0.770147 2023-10-16 05:17:57.074728 2023-10-16 05:18:04.603526   \n",
              "5        5  0.770249 2023-10-16 05:18:04.610633 2023-10-16 05:18:09.854469   \n",
              "6        6  0.770308 2023-10-16 05:18:09.856473 2023-10-16 05:18:15.394622   \n",
              "7        7  0.770166 2023-10-16 05:18:15.397002 2023-10-16 05:18:22.730216   \n",
              "8        8  0.770298 2023-10-16 05:18:22.732327 2023-10-16 05:18:29.056045   \n",
              "9        9  0.770317 2023-10-16 05:18:29.059035 2023-10-16 05:18:33.127555   \n",
              "10      10  0.770572 2023-10-16 05:18:33.129193 2023-10-16 05:18:37.198483   \n",
              "11      11  0.770641 2023-10-16 05:18:37.201930 2023-10-16 05:18:41.755840   \n",
              "12      12  0.770676 2023-10-16 05:18:41.759049 2023-10-16 05:18:46.430661   \n",
              "13      13  0.771084 2023-10-16 05:18:46.433147 2023-10-16 05:18:49.978342   \n",
              "14      14  0.770249 2023-10-16 05:18:49.980130 2023-10-16 05:18:56.868047   \n",
              "15      15  0.771160 2023-10-16 05:18:56.871044 2023-10-16 05:19:01.906256   \n",
              "16      16  0.770949 2023-10-16 05:19:01.908654 2023-10-16 05:19:05.472336   \n",
              "17      17  0.770334 2023-10-16 05:19:05.474301 2023-10-16 05:19:10.092180   \n",
              "18      18  0.770235 2023-10-16 05:19:10.099614 2023-10-16 05:19:17.693392   \n",
              "19      19  0.770387 2023-10-16 05:19:17.695401 2023-10-16 05:19:22.472010   \n",
              "20      20  0.770401 2023-10-16 05:19:22.474384 2023-10-16 05:19:27.506528   \n",
              "21      21  0.771109 2023-10-16 05:19:27.509490 2023-10-16 05:19:31.607828   \n",
              "22      22  0.770972 2023-10-16 05:19:31.609618 2023-10-16 05:19:35.513757   \n",
              "23      23  0.771050 2023-10-16 05:19:35.515552 2023-10-16 05:19:39.424631   \n",
              "24      24  0.771032 2023-10-16 05:19:39.427613 2023-10-16 05:19:44.268881   \n",
              "25      25  0.770991 2023-10-16 05:19:44.271325 2023-10-16 05:19:48.165582   \n",
              "26      26  0.770448 2023-10-16 05:19:48.167337 2023-10-16 05:19:52.397888   \n",
              "27      27  0.770515 2023-10-16 05:19:52.399649 2023-10-16 05:19:58.360388   \n",
              "28      28  0.770158 2023-10-16 05:19:58.363597 2023-10-16 05:20:04.850016   \n",
              "29      29  0.770353 2023-10-16 05:20:04.852202 2023-10-16 05:20:11.292418   \n",
              "30      30  0.770657 2023-10-16 05:20:11.295486 2023-10-16 05:20:15.902945   \n",
              "31      31  0.771094 2023-10-16 05:20:15.905472 2023-10-16 05:20:19.720480   \n",
              "32      32  0.771087 2023-10-16 05:20:19.722479 2023-10-16 05:20:23.534591   \n",
              "33      33  0.771120 2023-10-16 05:20:23.536382 2023-10-16 05:20:28.607995   \n",
              "34      34  0.770358 2023-10-16 05:20:28.609746 2023-10-16 05:20:34.163988   \n",
              "35      35  0.771067 2023-10-16 05:20:34.165746 2023-10-16 05:20:37.968617   \n",
              "36      36  0.770287 2023-10-16 05:20:37.970361 2023-10-16 05:20:45.131164   \n",
              "37      37  0.770467 2023-10-16 05:20:45.133027 2023-10-16 05:20:49.005788   \n",
              "38      38  0.770684 2023-10-16 05:20:49.007617 2023-10-16 05:20:53.005637   \n",
              "39      39  0.770302 2023-10-16 05:20:53.008135 2023-10-16 05:20:58.526900   \n",
              "40      40  0.770147 2023-10-16 05:20:58.528666 2023-10-16 05:21:04.840223   \n",
              "41      41  0.771056 2023-10-16 05:21:04.842054 2023-10-16 05:21:08.668007   \n",
              "42      42  0.771044 2023-10-16 05:21:08.675606 2023-10-16 05:21:13.675059   \n",
              "43      43  0.770980 2023-10-16 05:21:13.677298 2023-10-16 05:21:17.517016   \n",
              "44      44  0.770825 2023-10-16 05:21:17.518708 2023-10-16 05:21:21.465749   \n",
              "45      45  0.771194 2023-10-16 05:21:21.467508 2023-10-16 05:21:25.964086   \n",
              "46      46  0.771154 2023-10-16 05:21:25.967301 2023-10-16 05:21:30.252485   \n",
              "47      47  0.771143 2023-10-16 05:21:30.255650 2023-10-16 05:21:33.974639   \n",
              "48      48  0.770573 2023-10-16 05:21:33.976928 2023-10-16 05:21:38.175846   \n",
              "49      49  0.770255 2023-10-16 05:21:38.178789 2023-10-16 05:21:45.758167   \n",
              "\n",
              "                 duration  params_colsample_bytree  params_learning_rate  \\\n",
              "0  0 days 00:00:04.762683                 0.580134              0.171424   \n",
              "1  0 days 00:00:05.857501                 0.724044              0.184544   \n",
              "2  0 days 00:00:06.610240                 0.501949              0.197701   \n",
              "3  0 days 00:00:04.448063                 0.711485              0.135746   \n",
              "4  0 days 00:00:07.528798                 0.646875              0.257536   \n",
              "5  0 days 00:00:05.243836                 0.599159              0.156969   \n",
              "6  0 days 00:00:05.538149                 0.564816              0.128158   \n",
              "7  0 days 00:00:07.333214                 0.669799              0.233965   \n",
              "8  0 days 00:00:06.323718                 0.674883              0.223071   \n",
              "9  0 days 00:00:04.068520                 0.540370              0.239699   \n",
              "10 0 days 00:00:04.069290                 0.791004              0.066467   \n",
              "11 0 days 00:00:04.553910                 0.797715              0.061782   \n",
              "12 0 days 00:00:04.671612                 0.794073              0.052295   \n",
              "13 0 days 00:00:03.545195                 0.792487              0.001292   \n",
              "14 0 days 00:00:06.887917                 0.762060              0.018433   \n",
              "15 0 days 00:00:05.035212                 0.747269              0.018497   \n",
              "16 0 days 00:00:03.563682                 0.747485              0.003022   \n",
              "17 0 days 00:00:04.617879                 0.757093              0.102026   \n",
              "18 0 days 00:00:07.593778                 0.713271              0.006261   \n",
              "19 0 days 00:00:04.776609                 0.766060              0.035113   \n",
              "20 0 days 00:00:05.032144                 0.735205              0.083283   \n",
              "21 0 days 00:00:04.098338                 0.746296              0.006074   \n",
              "22 0 days 00:00:03.904139                 0.768709              0.038944   \n",
              "23 0 days 00:00:03.909079                 0.738157              0.026212   \n",
              "24 0 days 00:00:04.841268                 0.700715              0.001835   \n",
              "25 0 days 00:00:03.894257                 0.776256              0.037433   \n",
              "26 0 days 00:00:04.230551                 0.743007              0.081980   \n",
              "27 0 days 00:00:05.960739                 0.775884              0.019343   \n",
              "28 0 days 00:00:06.486419                 0.695891              0.041952   \n",
              "29 0 days 00:00:06.440216                 0.736477              0.001686   \n",
              "30 0 days 00:00:04.607459                 0.797822              0.055739   \n",
              "31 0 days 00:00:03.815008                 0.744550              0.023071   \n",
              "32 0 days 00:00:03.812112                 0.753055              0.022697   \n",
              "33 0 days 00:00:05.071613                 0.723301              0.026884   \n",
              "34 0 days 00:00:05.554242                 0.729248              0.046692   \n",
              "35 0 days 00:00:03.802871                 0.721500              0.024229   \n",
              "36 0 days 00:00:07.160803                 0.718341              0.075200   \n",
              "37 0 days 00:00:03.872761                 0.699490              0.101458   \n",
              "38 0 days 00:00:03.998020                 0.747904              0.057902   \n",
              "39 0 days 00:00:05.518765                 0.726994              0.290816   \n",
              "40 0 days 00:00:06.311557                 0.683783              0.028923   \n",
              "41 0 days 00:00:03.825953                 0.752342              0.021647   \n",
              "42 0 days 00:00:04.999453                 0.776451              0.015169   \n",
              "43 0 days 00:00:03.839718                 0.754781              0.036345   \n",
              "44 0 days 00:00:03.947041                 0.727386              0.046796   \n",
              "45 0 days 00:00:04.496578                 0.708318              0.016844   \n",
              "46 0 days 00:00:04.285184                 0.659455              0.014269   \n",
              "47 0 days 00:00:03.718989                 0.646821              0.010420   \n",
              "48 0 days 00:00:04.198918                 0.648780              0.068105   \n",
              "49 0 days 00:00:07.579378                 0.661665              0.048664   \n",
              "\n",
              "    params_max_depth  params_min_child_samples  params_num_leaves     state  \n",
              "0                 11                         8                512  COMPLETE  \n",
              "1                 11                        24                256  COMPLETE  \n",
              "2                 19                        70                256  COMPLETE  \n",
              "3                 12                        89                 64  COMPLETE  \n",
              "4                 19                        95                256  COMPLETE  \n",
              "5                 20                        35                128  COMPLETE  \n",
              "6                 18                        11                 64  COMPLETE  \n",
              "7                 20                        73                256  COMPLETE  \n",
              "8                 25                        71                 64  COMPLETE  \n",
              "9                 10                       100                128  COMPLETE  \n",
              "10                14                        53                 64  COMPLETE  \n",
              "11                14                        50                 64  COMPLETE  \n",
              "12                15                        49                 64  COMPLETE  \n",
              "13                15                        48                 64  COMPLETE  \n",
              "14                15                        44                512  COMPLETE  \n",
              "15                15                        58                 64  COMPLETE  \n",
              "16                16                        61                 64  COMPLETE  \n",
              "17                22                        23                 64  COMPLETE  \n",
              "18                17                        34                512  COMPLETE  \n",
              "19                13                        83                128  COMPLETE  \n",
              "20                17                        60                 64  COMPLETE  \n",
              "21                16                        60                 64  COMPLETE  \n",
              "22                16                        62                 64  COMPLETE  \n",
              "23                13                        40                 64  COMPLETE  \n",
              "24                15                        80                 64  COMPLETE  \n",
              "25                22                        55                 64  COMPLETE  \n",
              "26                16                        65                 64  COMPLETE  \n",
              "27                13                        26                128  COMPLETE  \n",
              "28                18                        78                512  COMPLETE  \n",
              "29                12                        45                512  COMPLETE  \n",
              "30                14                        56                 64  COMPLETE  \n",
              "31                13                        39                 64  COMPLETE  \n",
              "32                10                        33                 64  COMPLETE  \n",
              "33                10                        13                 64  COMPLETE  \n",
              "34                11                         8                256  COMPLETE  \n",
              "35                11                        19                 64  COMPLETE  \n",
              "36                12                         2                256  COMPLETE  \n",
              "37                10                        39                 64  COMPLETE  \n",
              "38                12                        15                 64  COMPLETE  \n",
              "39                13                        28                128  COMPLETE  \n",
              "40                19                         1                256  COMPLETE  \n",
              "41                10                        33                 64  COMPLETE  \n",
              "42                11                        30                 64  COMPLETE  \n",
              "43                10                        66                 64  COMPLETE  \n",
              "44                12                        41                 64  COMPLETE  \n",
              "45                14                        19                 64  COMPLETE  \n",
              "46                14                        14                 64  COMPLETE  \n",
              "47                14                        14                 64  COMPLETE  \n",
              "48                14                        13                 64  COMPLETE  \n",
              "49                14                        19                512  COMPLETE  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-79c097f6-221a-45a4-a295-3d2542234368\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>number</th>\n",
              "      <th>value</th>\n",
              "      <th>datetime_start</th>\n",
              "      <th>datetime_complete</th>\n",
              "      <th>duration</th>\n",
              "      <th>params_colsample_bytree</th>\n",
              "      <th>params_learning_rate</th>\n",
              "      <th>params_max_depth</th>\n",
              "      <th>params_min_child_samples</th>\n",
              "      <th>params_num_leaves</th>\n",
              "      <th>state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.770301</td>\n",
              "      <td>2023-10-16 05:17:35.387827</td>\n",
              "      <td>2023-10-16 05:17:40.150510</td>\n",
              "      <td>0 days 00:00:04.762683</td>\n",
              "      <td>0.580134</td>\n",
              "      <td>0.171424</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>512</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.770312</td>\n",
              "      <td>2023-10-16 05:17:40.152280</td>\n",
              "      <td>2023-10-16 05:17:46.009781</td>\n",
              "      <td>0 days 00:00:05.857501</td>\n",
              "      <td>0.724044</td>\n",
              "      <td>0.184544</td>\n",
              "      <td>11</td>\n",
              "      <td>24</td>\n",
              "      <td>256</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.770177</td>\n",
              "      <td>2023-10-16 05:17:46.011590</td>\n",
              "      <td>2023-10-16 05:17:52.621830</td>\n",
              "      <td>0 days 00:00:06.610240</td>\n",
              "      <td>0.501949</td>\n",
              "      <td>0.197701</td>\n",
              "      <td>19</td>\n",
              "      <td>70</td>\n",
              "      <td>256</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.770334</td>\n",
              "      <td>2023-10-16 05:17:52.623603</td>\n",
              "      <td>2023-10-16 05:17:57.071666</td>\n",
              "      <td>0 days 00:00:04.448063</td>\n",
              "      <td>0.711485</td>\n",
              "      <td>0.135746</td>\n",
              "      <td>12</td>\n",
              "      <td>89</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.770147</td>\n",
              "      <td>2023-10-16 05:17:57.074728</td>\n",
              "      <td>2023-10-16 05:18:04.603526</td>\n",
              "      <td>0 days 00:00:07.528798</td>\n",
              "      <td>0.646875</td>\n",
              "      <td>0.257536</td>\n",
              "      <td>19</td>\n",
              "      <td>95</td>\n",
              "      <td>256</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>0.770249</td>\n",
              "      <td>2023-10-16 05:18:04.610633</td>\n",
              "      <td>2023-10-16 05:18:09.854469</td>\n",
              "      <td>0 days 00:00:05.243836</td>\n",
              "      <td>0.599159</td>\n",
              "      <td>0.156969</td>\n",
              "      <td>20</td>\n",
              "      <td>35</td>\n",
              "      <td>128</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>0.770308</td>\n",
              "      <td>2023-10-16 05:18:09.856473</td>\n",
              "      <td>2023-10-16 05:18:15.394622</td>\n",
              "      <td>0 days 00:00:05.538149</td>\n",
              "      <td>0.564816</td>\n",
              "      <td>0.128158</td>\n",
              "      <td>18</td>\n",
              "      <td>11</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>0.770166</td>\n",
              "      <td>2023-10-16 05:18:15.397002</td>\n",
              "      <td>2023-10-16 05:18:22.730216</td>\n",
              "      <td>0 days 00:00:07.333214</td>\n",
              "      <td>0.669799</td>\n",
              "      <td>0.233965</td>\n",
              "      <td>20</td>\n",
              "      <td>73</td>\n",
              "      <td>256</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>0.770298</td>\n",
              "      <td>2023-10-16 05:18:22.732327</td>\n",
              "      <td>2023-10-16 05:18:29.056045</td>\n",
              "      <td>0 days 00:00:06.323718</td>\n",
              "      <td>0.674883</td>\n",
              "      <td>0.223071</td>\n",
              "      <td>25</td>\n",
              "      <td>71</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>0.770317</td>\n",
              "      <td>2023-10-16 05:18:29.059035</td>\n",
              "      <td>2023-10-16 05:18:33.127555</td>\n",
              "      <td>0 days 00:00:04.068520</td>\n",
              "      <td>0.540370</td>\n",
              "      <td>0.239699</td>\n",
              "      <td>10</td>\n",
              "      <td>100</td>\n",
              "      <td>128</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>0.770572</td>\n",
              "      <td>2023-10-16 05:18:33.129193</td>\n",
              "      <td>2023-10-16 05:18:37.198483</td>\n",
              "      <td>0 days 00:00:04.069290</td>\n",
              "      <td>0.791004</td>\n",
              "      <td>0.066467</td>\n",
              "      <td>14</td>\n",
              "      <td>53</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>0.770641</td>\n",
              "      <td>2023-10-16 05:18:37.201930</td>\n",
              "      <td>2023-10-16 05:18:41.755840</td>\n",
              "      <td>0 days 00:00:04.553910</td>\n",
              "      <td>0.797715</td>\n",
              "      <td>0.061782</td>\n",
              "      <td>14</td>\n",
              "      <td>50</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>0.770676</td>\n",
              "      <td>2023-10-16 05:18:41.759049</td>\n",
              "      <td>2023-10-16 05:18:46.430661</td>\n",
              "      <td>0 days 00:00:04.671612</td>\n",
              "      <td>0.794073</td>\n",
              "      <td>0.052295</td>\n",
              "      <td>15</td>\n",
              "      <td>49</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>0.771084</td>\n",
              "      <td>2023-10-16 05:18:46.433147</td>\n",
              "      <td>2023-10-16 05:18:49.978342</td>\n",
              "      <td>0 days 00:00:03.545195</td>\n",
              "      <td>0.792487</td>\n",
              "      <td>0.001292</td>\n",
              "      <td>15</td>\n",
              "      <td>48</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>0.770249</td>\n",
              "      <td>2023-10-16 05:18:49.980130</td>\n",
              "      <td>2023-10-16 05:18:56.868047</td>\n",
              "      <td>0 days 00:00:06.887917</td>\n",
              "      <td>0.762060</td>\n",
              "      <td>0.018433</td>\n",
              "      <td>15</td>\n",
              "      <td>44</td>\n",
              "      <td>512</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>0.771160</td>\n",
              "      <td>2023-10-16 05:18:56.871044</td>\n",
              "      <td>2023-10-16 05:19:01.906256</td>\n",
              "      <td>0 days 00:00:05.035212</td>\n",
              "      <td>0.747269</td>\n",
              "      <td>0.018497</td>\n",
              "      <td>15</td>\n",
              "      <td>58</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>0.770949</td>\n",
              "      <td>2023-10-16 05:19:01.908654</td>\n",
              "      <td>2023-10-16 05:19:05.472336</td>\n",
              "      <td>0 days 00:00:03.563682</td>\n",
              "      <td>0.747485</td>\n",
              "      <td>0.003022</td>\n",
              "      <td>16</td>\n",
              "      <td>61</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>0.770334</td>\n",
              "      <td>2023-10-16 05:19:05.474301</td>\n",
              "      <td>2023-10-16 05:19:10.092180</td>\n",
              "      <td>0 days 00:00:04.617879</td>\n",
              "      <td>0.757093</td>\n",
              "      <td>0.102026</td>\n",
              "      <td>22</td>\n",
              "      <td>23</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>0.770235</td>\n",
              "      <td>2023-10-16 05:19:10.099614</td>\n",
              "      <td>2023-10-16 05:19:17.693392</td>\n",
              "      <td>0 days 00:00:07.593778</td>\n",
              "      <td>0.713271</td>\n",
              "      <td>0.006261</td>\n",
              "      <td>17</td>\n",
              "      <td>34</td>\n",
              "      <td>512</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>0.770387</td>\n",
              "      <td>2023-10-16 05:19:17.695401</td>\n",
              "      <td>2023-10-16 05:19:22.472010</td>\n",
              "      <td>0 days 00:00:04.776609</td>\n",
              "      <td>0.766060</td>\n",
              "      <td>0.035113</td>\n",
              "      <td>13</td>\n",
              "      <td>83</td>\n",
              "      <td>128</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>0.770401</td>\n",
              "      <td>2023-10-16 05:19:22.474384</td>\n",
              "      <td>2023-10-16 05:19:27.506528</td>\n",
              "      <td>0 days 00:00:05.032144</td>\n",
              "      <td>0.735205</td>\n",
              "      <td>0.083283</td>\n",
              "      <td>17</td>\n",
              "      <td>60</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>0.771109</td>\n",
              "      <td>2023-10-16 05:19:27.509490</td>\n",
              "      <td>2023-10-16 05:19:31.607828</td>\n",
              "      <td>0 days 00:00:04.098338</td>\n",
              "      <td>0.746296</td>\n",
              "      <td>0.006074</td>\n",
              "      <td>16</td>\n",
              "      <td>60</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>0.770972</td>\n",
              "      <td>2023-10-16 05:19:31.609618</td>\n",
              "      <td>2023-10-16 05:19:35.513757</td>\n",
              "      <td>0 days 00:00:03.904139</td>\n",
              "      <td>0.768709</td>\n",
              "      <td>0.038944</td>\n",
              "      <td>16</td>\n",
              "      <td>62</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>0.771050</td>\n",
              "      <td>2023-10-16 05:19:35.515552</td>\n",
              "      <td>2023-10-16 05:19:39.424631</td>\n",
              "      <td>0 days 00:00:03.909079</td>\n",
              "      <td>0.738157</td>\n",
              "      <td>0.026212</td>\n",
              "      <td>13</td>\n",
              "      <td>40</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>0.771032</td>\n",
              "      <td>2023-10-16 05:19:39.427613</td>\n",
              "      <td>2023-10-16 05:19:44.268881</td>\n",
              "      <td>0 days 00:00:04.841268</td>\n",
              "      <td>0.700715</td>\n",
              "      <td>0.001835</td>\n",
              "      <td>15</td>\n",
              "      <td>80</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>25</td>\n",
              "      <td>0.770991</td>\n",
              "      <td>2023-10-16 05:19:44.271325</td>\n",
              "      <td>2023-10-16 05:19:48.165582</td>\n",
              "      <td>0 days 00:00:03.894257</td>\n",
              "      <td>0.776256</td>\n",
              "      <td>0.037433</td>\n",
              "      <td>22</td>\n",
              "      <td>55</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>26</td>\n",
              "      <td>0.770448</td>\n",
              "      <td>2023-10-16 05:19:48.167337</td>\n",
              "      <td>2023-10-16 05:19:52.397888</td>\n",
              "      <td>0 days 00:00:04.230551</td>\n",
              "      <td>0.743007</td>\n",
              "      <td>0.081980</td>\n",
              "      <td>16</td>\n",
              "      <td>65</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>27</td>\n",
              "      <td>0.770515</td>\n",
              "      <td>2023-10-16 05:19:52.399649</td>\n",
              "      <td>2023-10-16 05:19:58.360388</td>\n",
              "      <td>0 days 00:00:05.960739</td>\n",
              "      <td>0.775884</td>\n",
              "      <td>0.019343</td>\n",
              "      <td>13</td>\n",
              "      <td>26</td>\n",
              "      <td>128</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>28</td>\n",
              "      <td>0.770158</td>\n",
              "      <td>2023-10-16 05:19:58.363597</td>\n",
              "      <td>2023-10-16 05:20:04.850016</td>\n",
              "      <td>0 days 00:00:06.486419</td>\n",
              "      <td>0.695891</td>\n",
              "      <td>0.041952</td>\n",
              "      <td>18</td>\n",
              "      <td>78</td>\n",
              "      <td>512</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>29</td>\n",
              "      <td>0.770353</td>\n",
              "      <td>2023-10-16 05:20:04.852202</td>\n",
              "      <td>2023-10-16 05:20:11.292418</td>\n",
              "      <td>0 days 00:00:06.440216</td>\n",
              "      <td>0.736477</td>\n",
              "      <td>0.001686</td>\n",
              "      <td>12</td>\n",
              "      <td>45</td>\n",
              "      <td>512</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>30</td>\n",
              "      <td>0.770657</td>\n",
              "      <td>2023-10-16 05:20:11.295486</td>\n",
              "      <td>2023-10-16 05:20:15.902945</td>\n",
              "      <td>0 days 00:00:04.607459</td>\n",
              "      <td>0.797822</td>\n",
              "      <td>0.055739</td>\n",
              "      <td>14</td>\n",
              "      <td>56</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>31</td>\n",
              "      <td>0.771094</td>\n",
              "      <td>2023-10-16 05:20:15.905472</td>\n",
              "      <td>2023-10-16 05:20:19.720480</td>\n",
              "      <td>0 days 00:00:03.815008</td>\n",
              "      <td>0.744550</td>\n",
              "      <td>0.023071</td>\n",
              "      <td>13</td>\n",
              "      <td>39</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>32</td>\n",
              "      <td>0.771087</td>\n",
              "      <td>2023-10-16 05:20:19.722479</td>\n",
              "      <td>2023-10-16 05:20:23.534591</td>\n",
              "      <td>0 days 00:00:03.812112</td>\n",
              "      <td>0.753055</td>\n",
              "      <td>0.022697</td>\n",
              "      <td>10</td>\n",
              "      <td>33</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>33</td>\n",
              "      <td>0.771120</td>\n",
              "      <td>2023-10-16 05:20:23.536382</td>\n",
              "      <td>2023-10-16 05:20:28.607995</td>\n",
              "      <td>0 days 00:00:05.071613</td>\n",
              "      <td>0.723301</td>\n",
              "      <td>0.026884</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>34</td>\n",
              "      <td>0.770358</td>\n",
              "      <td>2023-10-16 05:20:28.609746</td>\n",
              "      <td>2023-10-16 05:20:34.163988</td>\n",
              "      <td>0 days 00:00:05.554242</td>\n",
              "      <td>0.729248</td>\n",
              "      <td>0.046692</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>256</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>35</td>\n",
              "      <td>0.771067</td>\n",
              "      <td>2023-10-16 05:20:34.165746</td>\n",
              "      <td>2023-10-16 05:20:37.968617</td>\n",
              "      <td>0 days 00:00:03.802871</td>\n",
              "      <td>0.721500</td>\n",
              "      <td>0.024229</td>\n",
              "      <td>11</td>\n",
              "      <td>19</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>36</td>\n",
              "      <td>0.770287</td>\n",
              "      <td>2023-10-16 05:20:37.970361</td>\n",
              "      <td>2023-10-16 05:20:45.131164</td>\n",
              "      <td>0 days 00:00:07.160803</td>\n",
              "      <td>0.718341</td>\n",
              "      <td>0.075200</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>256</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>37</td>\n",
              "      <td>0.770467</td>\n",
              "      <td>2023-10-16 05:20:45.133027</td>\n",
              "      <td>2023-10-16 05:20:49.005788</td>\n",
              "      <td>0 days 00:00:03.872761</td>\n",
              "      <td>0.699490</td>\n",
              "      <td>0.101458</td>\n",
              "      <td>10</td>\n",
              "      <td>39</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>38</td>\n",
              "      <td>0.770684</td>\n",
              "      <td>2023-10-16 05:20:49.007617</td>\n",
              "      <td>2023-10-16 05:20:53.005637</td>\n",
              "      <td>0 days 00:00:03.998020</td>\n",
              "      <td>0.747904</td>\n",
              "      <td>0.057902</td>\n",
              "      <td>12</td>\n",
              "      <td>15</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>39</td>\n",
              "      <td>0.770302</td>\n",
              "      <td>2023-10-16 05:20:53.008135</td>\n",
              "      <td>2023-10-16 05:20:58.526900</td>\n",
              "      <td>0 days 00:00:05.518765</td>\n",
              "      <td>0.726994</td>\n",
              "      <td>0.290816</td>\n",
              "      <td>13</td>\n",
              "      <td>28</td>\n",
              "      <td>128</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>40</td>\n",
              "      <td>0.770147</td>\n",
              "      <td>2023-10-16 05:20:58.528666</td>\n",
              "      <td>2023-10-16 05:21:04.840223</td>\n",
              "      <td>0 days 00:00:06.311557</td>\n",
              "      <td>0.683783</td>\n",
              "      <td>0.028923</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>256</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>41</td>\n",
              "      <td>0.771056</td>\n",
              "      <td>2023-10-16 05:21:04.842054</td>\n",
              "      <td>2023-10-16 05:21:08.668007</td>\n",
              "      <td>0 days 00:00:03.825953</td>\n",
              "      <td>0.752342</td>\n",
              "      <td>0.021647</td>\n",
              "      <td>10</td>\n",
              "      <td>33</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>42</td>\n",
              "      <td>0.771044</td>\n",
              "      <td>2023-10-16 05:21:08.675606</td>\n",
              "      <td>2023-10-16 05:21:13.675059</td>\n",
              "      <td>0 days 00:00:04.999453</td>\n",
              "      <td>0.776451</td>\n",
              "      <td>0.015169</td>\n",
              "      <td>11</td>\n",
              "      <td>30</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>43</td>\n",
              "      <td>0.770980</td>\n",
              "      <td>2023-10-16 05:21:13.677298</td>\n",
              "      <td>2023-10-16 05:21:17.517016</td>\n",
              "      <td>0 days 00:00:03.839718</td>\n",
              "      <td>0.754781</td>\n",
              "      <td>0.036345</td>\n",
              "      <td>10</td>\n",
              "      <td>66</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>44</td>\n",
              "      <td>0.770825</td>\n",
              "      <td>2023-10-16 05:21:17.518708</td>\n",
              "      <td>2023-10-16 05:21:21.465749</td>\n",
              "      <td>0 days 00:00:03.947041</td>\n",
              "      <td>0.727386</td>\n",
              "      <td>0.046796</td>\n",
              "      <td>12</td>\n",
              "      <td>41</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>45</td>\n",
              "      <td>0.771194</td>\n",
              "      <td>2023-10-16 05:21:21.467508</td>\n",
              "      <td>2023-10-16 05:21:25.964086</td>\n",
              "      <td>0 days 00:00:04.496578</td>\n",
              "      <td>0.708318</td>\n",
              "      <td>0.016844</td>\n",
              "      <td>14</td>\n",
              "      <td>19</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>46</td>\n",
              "      <td>0.771154</td>\n",
              "      <td>2023-10-16 05:21:25.967301</td>\n",
              "      <td>2023-10-16 05:21:30.252485</td>\n",
              "      <td>0 days 00:00:04.285184</td>\n",
              "      <td>0.659455</td>\n",
              "      <td>0.014269</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>47</td>\n",
              "      <td>0.771143</td>\n",
              "      <td>2023-10-16 05:21:30.255650</td>\n",
              "      <td>2023-10-16 05:21:33.974639</td>\n",
              "      <td>0 days 00:00:03.718989</td>\n",
              "      <td>0.646821</td>\n",
              "      <td>0.010420</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>48</td>\n",
              "      <td>0.770573</td>\n",
              "      <td>2023-10-16 05:21:33.976928</td>\n",
              "      <td>2023-10-16 05:21:38.175846</td>\n",
              "      <td>0 days 00:00:04.198918</td>\n",
              "      <td>0.648780</td>\n",
              "      <td>0.068105</td>\n",
              "      <td>14</td>\n",
              "      <td>13</td>\n",
              "      <td>64</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>49</td>\n",
              "      <td>0.770255</td>\n",
              "      <td>2023-10-16 05:21:38.178789</td>\n",
              "      <td>2023-10-16 05:21:45.758167</td>\n",
              "      <td>0 days 00:00:07.579378</td>\n",
              "      <td>0.661665</td>\n",
              "      <td>0.048664</td>\n",
              "      <td>14</td>\n",
              "      <td>19</td>\n",
              "      <td>512</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79c097f6-221a-45a4-a295-3d2542234368')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-79c097f6-221a-45a4-a295-3d2542234368 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-79c097f6-221a-45a4-a295-3d2542234368');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-54eee0ff-6a53-46a4-9767-9739be2b3082\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-54eee0ff-6a53-46a4-9767-9739be2b3082')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-54eee0ff-6a53-46a4-9767-9739be2b3082 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# is_balance=True\n",
        "print('Best Score: %.4f' % study.best_value)\n",
        "print('Best Params: ', study.best_trial.params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiBHdSXd9ZuY",
        "outputId": "70a02b4d-30b0-4fc5-dee3-50b335d1b920"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Score: 0.7712\n",
            "Best Params:  {'num_leaves': 64, 'max_depth': 14, 'learning_rate': 0.016844006148382676, 'min_child_samples': 19, 'colsample_bytree': 0.7083179082542116}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fix learning rate 0.016844006148382676\n",
        "print('Best Score: %.4f' % study.best_value)\n",
        "print('Best Params: ', study.best_trial.params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQj3JE3qJsUH",
        "outputId": "7bbd86d9-e413-4ab3-fe12-53f1040e892a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Score: 0.7712\n",
            "Best Params:  {'num_leaves': 64, 'max_depth': 14, 'min_child_samples': 46, 'colsample_bytree': 0.7443738203689874}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fix learning rate 0.016844006148382676, num_leaves 64\n",
        "print('Best Score: %.4f' % study.best_value)\n",
        "print('Best Params: ', study.best_trial.params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPRUvZ3iKTCK",
        "outputId": "724b9bce-7444-4f0f-f860-7aeefbbbac7b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Score: 0.7712\n",
            "Best Params:  {'max_depth': 21, 'min_child_samples': 52, 'colsample_bytree': 0.5779275403612723}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Best Score: %.4f' % study.best_value)\n",
        "print('Best Params: ', study.best_trial.params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U35c0pdILHGw",
        "outputId": "25eeb2a7-f37d-4ef5-cbb0-e7da8aa7af83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Score: 0.7923\n",
            "Best Params:  {'num_leaves': 64, 'max_depth': 14, 'learning_rate': 0.04151372498765896, 'min_child_samples': 64, 'colsample_bytree': 0.7039329213868132}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use pipeline for standardscaler\n",
        "print('Best Score: %.4f' % study.best_value)\n",
        "print('Best Params: ', study.best_trial.params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OKClPwpYJp_",
        "outputId": "f8608f2d-2f77-4c48-de13-6786ba6f5b62"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Score: 0.7845\n",
            "Best Params:  {'num_leaves': 64, 'max_depth': 22, 'learning_rate': 0.030278064653420228, 'min_child_samples': 30, 'colsample_bytree': 0.7974305378631804}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use pipeline for standardscaler & fix learning_rate 0.030278064653420228\n",
        "print('Best Score: %.4f' % study.best_value)\n",
        "print('Best Params: ', study.best_trial.params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGQR1CcHYTHm",
        "outputId": "b3437674-fb81-4c0a-bcbb-c548da6dadbf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Score: 0.7847\n",
            "Best Params:  {'num_leaves': 64, 'max_depth': 14, 'min_child_samples': 42, 'colsample_bytree': 0.7617328222470997}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use pipeline for standardscaler & fix learning_rate 0.030278064653420228 & num_leaves 64\n",
        "print('Best Score: %.4f' % study.best_value)\n",
        "print('Best Params: ', study.best_trial.params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ou8ZGlT3bDVa",
        "outputId": "a0d573b1-8293-436c-c71b-d817decead80"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Score: 0.7846\n",
            "Best Params:  {'max_depth': 20, 'min_child_samples': 61, 'colsample_bytree': 0.7234385199718164}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optuna.visualization.plot_optimization_history(study)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "QErC9E7X9lgA",
        "outputId": "3768e3c5-65ae-4e15-c482-7c0ae4ec4c67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"86c0bc86-29ae-4f42-91d2-0a0fcb3e9dff\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"86c0bc86-29ae-4f42-91d2-0a0fcb3e9dff\")) {                    Plotly.newPlot(                        \"86c0bc86-29ae-4f42-91d2-0a0fcb3e9dff\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"y\":[0.7852445361650424,0.7894030324760755,0.7817712769887073,0.7873095294579161,0.7762375854399464,0.7874288121741377,0.7857429350705868,0.7879088505721772,0.782926646861107,0.7914780187110558,0.790213635179976,0.7916045548319979,0.7905787044772623,0.7914628930840228,0.7918948986238445,0.7882581852253663,0.7919748260831949,0.7922992424338606,0.7898396225665787,0.7877071846223563,0.7901189489109237,0.7919217781451794,0.7920917774204107,0.7916867481950333,0.7921244417176092,0.7918782677625302,0.7916311347328833,0.7876763268434951,0.787942045747195,0.7915920975864325,0.791962837900602,0.7921096516149794,0.791590844293012,0.7915456607700484,0.7901702100615126,0.7920893590416282,0.7911895334462276,0.7893947914378276,0.786544257567059,0.7862472842878983,0.7825144309012286,0.7920950804802549,0.79178691390029,0.7918046701102421,0.7921908896629896,0.7908974195318031,0.7918994795349971,0.7920335770384781,0.7910663721676797,0.7913666506579916],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"y\":[0.7852445361650424,0.7894030324760755,0.7894030324760755,0.7894030324760755,0.7894030324760755,0.7894030324760755,0.7894030324760755,0.7894030324760755,0.7894030324760755,0.7914780187110558,0.7914780187110558,0.7916045548319979,0.7916045548319979,0.7916045548319979,0.7918948986238445,0.7918948986238445,0.7919748260831949,0.7922992424338606,0.7922992424338606,0.7922992424338606,0.7922992424338606,0.7922992424338606,0.7922992424338606,0.7922992424338606,0.7922992424338606,0.7922992424338606,0.7922992424338606,0.7922992424338606,0.7922992424338606,0.7922992424338606,0.7922992424338606,0.7922992424338606,0.7922992424338606,0.7922992424338606,0.7922992424338606,0.7922992424338606,0.7922992424338606,0.7922992424338606,0.7922992424338606,0.7922992424338606,0.7922992424338606,0.7922992424338606,0.7922992424338606,0.7922992424338606,0.7922992424338606,0.7922992424338606,0.7922992424338606,0.7922992424338606,0.7922992424338606,0.7922992424338606],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#cccccc\"},\"mode\":\"markers\",\"name\":\"Infeasible Trial\",\"showlegend\":false,\"x\":[],\"y\":[],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('86c0bc86-29ae-4f42-91d2-0a0fcb3e9dff');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hyper-parameter들의 중요도\n",
        "optuna.visualization.plot_param_importances(study)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "DafloIvH2DdI",
        "outputId": "536ce883-91eb-4711-c916-037a4b334677"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"b87c56f7-b556-4f88-8171-4df322ddb843\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b87c56f7-b556-4f88-8171-4df322ddb843\")) {                    Plotly.newPlot(                        \"b87c56f7-b556-4f88-8171-4df322ddb843\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"max_depth (IntDistribution): 0.007634354283559574\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"min_child_samples (IntDistribution): 0.016145439837988496\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"colsample_bytree (FloatDistribution): 0.02335007669914093\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"num_leaves (CategoricalDistribution): 0.952870129179311\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"],\"marker\":{\"color\":\"rgb(66,146,198)\"},\"orientation\":\"h\",\"text\":[\"\\u003c0.01\",\"0.02\",\"0.02\",\"0.95\"],\"textposition\":\"outside\",\"x\":[0.007634354283559574,0.016145439837988496,0.02335007669914093,0.952870129179311],\"y\":[\"max_depth\",\"min_child_samples\",\"colsample_bytree\",\"num_leaves\"],\"type\":\"bar\"}],                        {\"showlegend\":false,\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Importance for Objective Value\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b87c56f7-b556-4f88-8171-4df322ddb843');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test & Submission file"
      ],
      "metadata": {
        "id": "4vihPqM1Gs4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def oof_preds(best_model) :\n",
        "  folds = StratifiedKFold(shuffle=True, random_state=61)\n",
        "  final_preds = []\n",
        "  auc_list = []\n",
        "\n",
        "  for i, (train_idx, val_idx) in enumerate(folds.split(X, y)) :\n",
        "    X_train = X.iloc[train_idx, :]\n",
        "    y_train = y.iloc[train_idx]\n",
        "    X_val = X.iloc[val_idx, :]\n",
        "    y_val = y.iloc[val_idx]\n",
        "\n",
        "    print(f\"========== Fold {i+1} ==========\")\n",
        "    best_model.fit(X_train, y_train)\n",
        "    preds = best_model.predict_proba(X_val)[:, 1]\n",
        "    test_preds = best_model.predict_proba(test)[:, 1]\n",
        "    final_preds.append(test_preds)\n",
        "    auc = roc_auc_score(y_val, preds)\n",
        "\n",
        "    auc_list.append(auc)\n",
        "\n",
        "  print(f'AUC :', np.mean(auc))\n",
        "  return final_preds"
      ],
      "metadata": {
        "id": "wFaFEGes9tyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = study.best_trial.params\n",
        "\n",
        "best_model = LGBMClassifier(**best_params,\n",
        "                            random_state=61)\n",
        "\n",
        "preds = oof_preds(best_model)\n",
        "preds = np.mean(preds, axis=0)\n",
        "\n",
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCnH0oIoIbK0",
        "outputId": "cf876a41-c50e-4700-8358-4ef039cbe4ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== Fold 1 ==========\n",
            "[LightGBM] [Info] Number of positive: 18451, number of negative: 62959\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019327 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3547\n",
            "[LightGBM] [Info] Number of data points in the train set: 81410, number of used features: 21\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226643 -> initscore=-1.227365\n",
            "[LightGBM] [Info] Start training from score -1.227365\n",
            "========== Fold 2 ==========\n",
            "[LightGBM] [Info] Number of positive: 18451, number of negative: 62959\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017872 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3546\n",
            "[LightGBM] [Info] Number of data points in the train set: 81410, number of used features: 21\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226643 -> initscore=-1.227365\n",
            "[LightGBM] [Info] Start training from score -1.227365\n",
            "========== Fold 3 ==========\n",
            "[LightGBM] [Info] Number of positive: 18451, number of negative: 62959\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017735 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3551\n",
            "[LightGBM] [Info] Number of data points in the train set: 81410, number of used features: 21\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226643 -> initscore=-1.227365\n",
            "[LightGBM] [Info] Start training from score -1.227365\n",
            "========== Fold 4 ==========\n",
            "[LightGBM] [Info] Number of positive: 18452, number of negative: 62959\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017711 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3558\n",
            "[LightGBM] [Info] Number of data points in the train set: 81411, number of used features: 21\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226652 -> initscore=-1.227311\n",
            "[LightGBM] [Info] Start training from score -1.227311\n",
            "========== Fold 5 ==========\n",
            "[LightGBM] [Info] Number of positive: 18451, number of negative: 62960\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028346 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3552\n",
            "[LightGBM] [Info] Number of data points in the train set: 81411, number of used features: 21\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.226640 -> initscore=-1.227381\n",
            "[LightGBM] [Info] Start training from score -1.227381\n",
            "AUC : 0.7848186877619578\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.21875383, 0.18928986, 0.64816721, ..., 0.17000563, 0.10214024,\n",
              "       0.80084926])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission.defects = preds"
      ],
      "metadata": {
        "id": "By566me_J7lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv('submission_lightGBM_allparameters.csv')"
      ],
      "metadata": {
        "id": "ul-pt-04J_IW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ROR1NfsIN4w2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}