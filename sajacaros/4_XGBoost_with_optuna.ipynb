{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f3119aa",
   "metadata": {
    "id": "8f3119aa"
   },
   "source": [
    "## Machine Learning 프로젝트 수행을 위한 코드 구조화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7610ea",
   "metadata": {
    "id": "9f7610ea"
   },
   "source": [
    "- ML project를 위해서 사용하는 템플릿 코드를 만듭니다.\n",
    "\n",
    "1. **필요한 라이브러리와 데이터를 불러옵니다.**\n",
    "\n",
    "\n",
    "2. **EDA를 수행합니다.** 이 때 EDA의 목적은 풀어야하는 문제를 위해서 수행됩니다.\n",
    "\n",
    "\n",
    "3. **전처리를 수행합니다.** 이 때 중요한건 **feature engineering**을 어떻게 하느냐 입니다.\n",
    "\n",
    "\n",
    "4. **데이터 분할을 합니다.** 이 때 train data와 test data 간의 분포 차이가 없는지 확인합니다.\n",
    "\n",
    "\n",
    "5. **학습을 진행합니다.** 어떤 모델을 사용하여 학습할지 정합니다. 성능이 잘 나오는 GBM을 추천합니다.\n",
    "\n",
    "\n",
    "6. **hyper-parameter tuning을 수행합니다.** 원하는 목표 성능이 나올 때 까지 진행합니다. 검증 단계를 통해 지속적으로 **overfitting이 되지 않게 주의**하세요.\n",
    "\n",
    "\n",
    "7. **최종 테스트를 진행합니다.** 데이터 분석 대회 포맷에 맞는 submission 파일을 만들어서 성능을 확인해보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2f7530",
   "metadata": {
    "id": "bd2f7530"
   },
   "source": [
    "## 1. 라이브러리, 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "125fc348",
   "metadata": {
    "id": "125fc348"
   },
   "outputs": [],
   "source": [
    "# 데이터분석 4종 세트\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 모델들, 성능 평가\n",
    "# (저는 일반적으로 정형데이터로 머신러닝 분석할 때는 이 2개 모델은 그냥 돌려봅니다. 특히 RF가 테스트하기 좋습니다.)\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# KFold(CV), partial : optuna를 사용하기 위함\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from functools import partial\n",
    "\n",
    "# hyper-parameter tuning을 위한 라이브러리, optuna\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3615c24a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3615c24a",
    "outputId": "6dc93ad0-06c8-4ee0-a96d-8d9a5dd6ddaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101763, 23) (67842, 22) (67842, 2)\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 불러옵니다.\n",
    "base_path = '../data/'\n",
    "train = pd.read_csv(base_path + 'train.csv')\n",
    "test = pd.read_csv(base_path + 'test.csv')\n",
    "submission = pd.read_csv(base_path + 'sample_submission.csv')\n",
    "print(train.shape, test.shape, submission.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c9acb8",
   "metadata": {
    "id": "c9c9acb8"
   },
   "source": [
    "## 2. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdf620b",
   "metadata": {
    "id": "6fdf620b"
   },
   "source": [
    "- 데이터에서 찾아야 하는 기초적인 내용들을 확인합니다.\n",
    "\n",
    "\n",
    "- class imbalance, target distribution, outlier, correlation을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train.columns"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R1TxMunIv4zb",
    "outputId": "56e20880-07fb-4f2a-c614-ef0c3202a0d0"
   },
   "id": "R1TxMunIv4zb",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['id', 'loc', 'v(g)', 'ev(g)', 'iv(g)', 'n', 'v', 'l', 'd', 'i', 'e',\n       'b', 't', 'lOCode', 'lOComment', 'lOBlank', 'locCodeAndComment',\n       'uniq_Op', 'uniq_Opnd', 'total_Op', 'total_Opnd', 'branchCount',\n       'defects'],\n      dtype='object')"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbb8802",
   "metadata": {
    "id": "9dbb8802"
   },
   "source": [
    "### 3. 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79a6f0a",
   "metadata": {
    "id": "b79a6f0a"
   },
   "source": [
    "#### 결측치 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f497a2d8",
   "metadata": {
    "id": "f497a2d8"
   },
   "source": [
    "### 4. 학습 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "47306aaf",
   "metadata": {
    "id": "47306aaf"
   },
   "outputs": [],
   "source": [
    "# 첫번째 테스트용으로 사용하고, 실제 학습시에는 K-Fold CV를 사용합니다.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train.drop(columns=['defects'])\n",
    "y = train.defects\n",
    "\n",
    "# for OOF-prediction split 5% of data as validation dataset.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=61, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "67efd2ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "67efd2ee",
    "outputId": "a8a904f0-8109-4e87-b0d8-81d97dde4a49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81410, 22) (81410,) (20353, 22) (20353,)\n",
      "0.2266429185603734 0.22664963396059548\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)\n",
    "print(y_train.mean(), y_val.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58056e51",
   "metadata": {
    "id": "58056e51"
   },
   "source": [
    "### 5. 학습 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "39fd2515",
   "metadata": {
    "id": "39fd2515"
   },
   "outputs": [],
   "source": [
    "# 간단하게 LightGBM 테스트\n",
    "# 적당한 hyper-parameter 조합을 두었습니다. (항상 best는 아닙니다. 예시입니다.)\n",
    "model = XGBClassifier(\n",
    "    booster='gbtree',\n",
    "    objective='binary:logistic',\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    n_jobs=-1,\n",
    "    random_state=61\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ddffa474",
   "metadata": {
    "scrolled": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "ddffa474",
    "outputId": "4e723622-af5a-4fea-9cd4-dfcd3c65630a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting LightGBM...\n"
     ]
    },
    {
     "data": {
      "text/plain": "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=6, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n              predictor=None, random_state=61, ...)",
      "text/html": "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=6, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n              predictor=None, random_state=61, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=6, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n              predictor=None, random_state=61, ...)</pre></div></div></div></div></div>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nFitting LightGBM...\")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6c8b0259",
   "metadata": {
    "id": "6c8b0259"
   },
   "outputs": [],
   "source": [
    "# metric은 그때마다 맞게 바꿔줘야 합니다.\n",
    "evaluation_metric = roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a6b39be5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6b39be5",
    "outputId": "2e2c256f-fe78-4deb-8fab-727306e3ffec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "Train Score : 0.6810\n",
      "Validation Score : 0.6668\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction\")\n",
    "pred_train = model.predict(X_train)\n",
    "pred_val = model.predict(X_val)\n",
    "\n",
    "\n",
    "train_score = evaluation_metric(y_train, pred_train)\n",
    "val_score = evaluation_metric(y_val, pred_val)\n",
    "\n",
    "print(\"Train Score : %.4f\" % train_score)\n",
    "print(\"Validation Score : %.4f\" % val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc755b17",
   "metadata": {
    "id": "bc755b17"
   },
   "source": [
    "### 6. Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "34ce4986",
   "metadata": {
    "id": "34ce4986"
   },
   "outputs": [],
   "source": [
    "def optimizer(trial, X, y, K):\n",
    "    # 조절할 hyper-parameter 조합을 적어줍니다.\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 15)\n",
    "    colsample_bynode = trial.suggest_float('colsample_bynode', 0.5, 0.8)\n",
    "    reg_lambda = trial.suggest_float('reg_lambda', 0.5, 5.0)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 1000)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3)\n",
    "\n",
    "    # 원하는 모델을 지정합니다, optuna는 시간이 오래걸리기 때문에 저는 보통 RF로 일단 테스트를 해본 뒤에 LGBM을 사용합니다.\n",
    "    model = XGBClassifier(\n",
    "        max_depth=max_depth,\n",
    "        colsample_bynode=colsample_bynode,\n",
    "        reg_lambda=reg_lambda,\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        random_state=61,\n",
    "        eval_metric=evaluation_metric,\n",
    "    )\n",
    "\n",
    "    # K-Fold Cross validation을 구현합니다.\n",
    "    folds = StratifiedKFold(n_splits=K, random_state=61, shuffle=True)\n",
    "    losses = []\n",
    "\n",
    "    for train_idx, val_idx in folds.split(X, y):\n",
    "        X_train = X.iloc[train_idx, :]\n",
    "        y_train = y.iloc[train_idx]\n",
    "\n",
    "        X_val = X.iloc[val_idx, :]\n",
    "        y_val = y.iloc[val_idx]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_val)\n",
    "        loss = evaluation_metric(y_val, preds)\n",
    "        losses.append(loss)\n",
    "\n",
    "\n",
    "    # K-Fold의 평균 loss값을 돌려줍니다.\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7150b210",
   "metadata": {
    "scrolled": false,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7150b210",
    "outputId": "fa1c663f-0f17-4f21-8016-ac43d456666d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-12 14:56:42,775] A new study created in memory with name: no-name-71bd27b7-1a5f-4e84-963d-0a7ba3ac0092\n",
      "[I 2023-10-12 14:57:20,620] Trial 0 finished with value: 0.6570820404811688 and parameters: {'max_depth': 10, 'colsample_bynode': 0.6527806841449566, 'reg_lambda': 4.123427390080673, 'n_estimators': 118, 'learning_rate': 0.22144245045640804}. Best is trial 0 with value: 0.6570820404811688.\n",
      "[I 2023-10-12 15:03:38,066] Trial 1 finished with value: 0.6524280341374044 and parameters: {'max_depth': 13, 'colsample_bynode': 0.5807836985163611, 'reg_lambda': 0.5803673820441073, 'n_estimators': 966, 'learning_rate': 0.21702513139757007}. Best is trial 0 with value: 0.6570820404811688.\n",
      "[I 2023-10-12 15:04:55,717] Trial 2 finished with value: 0.661503931030469 and parameters: {'max_depth': 14, 'colsample_bynode': 0.7517793825465595, 'reg_lambda': 1.4908876418319543, 'n_estimators': 104, 'learning_rate': 0.04302162358741328}. Best is trial 2 with value: 0.661503931030469.\n",
      "[I 2023-10-12 15:06:14,099] Trial 3 finished with value: 0.6628830319129408 and parameters: {'max_depth': 10, 'colsample_bynode': 0.632792969402846, 'reg_lambda': 4.56539759796926, 'n_estimators': 203, 'learning_rate': 0.03686296233704675}. Best is trial 3 with value: 0.6628830319129408.\n",
      "[I 2023-10-12 15:07:11,762] Trial 4 finished with value: 0.6600588448669822 and parameters: {'max_depth': 5, 'colsample_bynode': 0.6800950499183064, 'reg_lambda': 4.19856069892256, 'n_estimators': 353, 'learning_rate': 0.1361097120783677}. Best is trial 3 with value: 0.6628830319129408.\n",
      "[I 2023-10-12 15:08:08,467] Trial 5 finished with value: 0.6559640393529756 and parameters: {'max_depth': 11, 'colsample_bynode': 0.723493097600084, 'reg_lambda': 2.1078286920161253, 'n_estimators': 128, 'learning_rate': 0.2513229842377963}. Best is trial 3 with value: 0.6628830319129408.\n",
      "[I 2023-10-12 15:12:22,804] Trial 6 finished with value: 0.6570831724706112 and parameters: {'max_depth': 15, 'colsample_bynode': 0.7382879234382875, 'reg_lambda': 4.058388327321042, 'n_estimators': 407, 'learning_rate': 0.1156019576220292}. Best is trial 3 with value: 0.6628830319129408.\n",
      "[I 2023-10-12 15:19:06,232] Trial 7 finished with value: 0.6587627080157137 and parameters: {'max_depth': 12, 'colsample_bynode': 0.7779359456450936, 'reg_lambda': 3.7607893372015986, 'n_estimators': 784, 'learning_rate': 0.03537511279889113}. Best is trial 3 with value: 0.6628830319129408.\n",
      "[I 2023-10-12 15:23:11,329] Trial 8 finished with value: 0.6535911610395503 and parameters: {'max_depth': 10, 'colsample_bynode': 0.7664201716275063, 'reg_lambda': 3.89797057421871, 'n_estimators': 621, 'learning_rate': 0.24781878985595127}. Best is trial 3 with value: 0.6628830319129408.\n",
      "[I 2023-10-12 15:23:22,271] Trial 9 finished with value: 0.6648864168198861 and parameters: {'max_depth': 6, 'colsample_bynode': 0.7174997894450063, 'reg_lambda': 2.174700367871662, 'n_estimators': 50, 'learning_rate': 0.19621293974507872}. Best is trial 9 with value: 0.6648864168198861.\n",
      "[I 2023-10-12 15:24:43,122] Trial 10 finished with value: 0.6550816505446537 and parameters: {'max_depth': 5, 'colsample_bynode': 0.5703948779701368, 'reg_lambda': 2.933015805557656, 'n_estimators': 544, 'learning_rate': 0.29859056872534684}. Best is trial 9 with value: 0.6648864168198861.\n",
      "[I 2023-10-12 15:25:57,098] Trial 11 finished with value: 0.6591498687583354 and parameters: {'max_depth': 8, 'colsample_bynode': 0.6196110933365155, 'reg_lambda': 2.9718105338348386, 'n_estimators': 280, 'learning_rate': 0.08172004015206372}. Best is trial 9 with value: 0.6648864168198861.\n",
      "[I 2023-10-12 15:26:12,479] Trial 12 finished with value: 0.6649352398179343 and parameters: {'max_depth': 7, 'colsample_bynode': 0.6889342919030252, 'reg_lambda': 4.610786397554705, 'n_estimators': 55, 'learning_rate': 0.010533626220744788}. Best is trial 12 with value: 0.6649352398179343.\n",
      "[I 2023-10-12 15:26:26,184] Trial 13 finished with value: 0.664054771056285 and parameters: {'max_depth': 7, 'colsample_bynode': 0.6880205105483028, 'reg_lambda': 4.934991237945493, 'n_estimators': 52, 'learning_rate': 0.16925918070469925}. Best is trial 12 with value: 0.6649352398179343.\n",
      "[I 2023-10-12 15:27:25,229] Trial 14 finished with value: 0.6658872614472943 and parameters: {'max_depth': 7, 'colsample_bynode': 0.5264320420163437, 'reg_lambda': 3.402865922713856, 'n_estimators': 254, 'learning_rate': 0.01347624434428978}. Best is trial 14 with value: 0.6658872614472943.\n",
      "[I 2023-10-12 15:28:34,305] Trial 15 finished with value: 0.6654218943947247 and parameters: {'max_depth': 7, 'colsample_bynode': 0.5000100449567454, 'reg_lambda': 3.3836264927333812, 'n_estimators': 300, 'learning_rate': 0.01643982572817994}. Best is trial 14 with value: 0.6658872614472943.\n",
      "[I 2023-10-12 15:30:22,593] Trial 16 finished with value: 0.6591639955814486 and parameters: {'max_depth': 8, 'colsample_bynode': 0.512568305903368, 'reg_lambda': 3.3289693191281766, 'n_estimators': 447, 'learning_rate': 0.08065324371153587}. Best is trial 14 with value: 0.6658872614472943.\n",
      "[I 2023-10-12 15:31:44,515] Trial 17 finished with value: 0.6653389533450451 and parameters: {'max_depth': 8, 'colsample_bynode': 0.5010669313452608, 'reg_lambda': 3.3203917969304344, 'n_estimators': 291, 'learning_rate': 0.01341368390831564}. Best is trial 14 with value: 0.6658872614472943.\n",
      "[I 2023-10-12 15:34:26,742] Trial 18 finished with value: 0.658709214406495 and parameters: {'max_depth': 9, 'colsample_bynode': 0.5406549738958122, 'reg_lambda': 3.484489050993842, 'n_estimators': 587, 'learning_rate': 0.07364405504003564}. Best is trial 14 with value: 0.6658872614472943.\n",
      "[I 2023-10-12 15:35:05,107] Trial 19 finished with value: 0.6624669108249314 and parameters: {'max_depth': 6, 'colsample_bynode': 0.5363208341281865, 'reg_lambda': 2.674497911594817, 'n_estimators': 216, 'learning_rate': 0.10761625409752594}. Best is trial 14 with value: 0.6658872614472943.\n",
      "[I 2023-10-12 15:37:33,660] Trial 20 finished with value: 0.6589719054304254 and parameters: {'max_depth': 7, 'colsample_bynode': 0.5039155035744891, 'reg_lambda': 3.6390434386123047, 'n_estimators': 698, 'learning_rate': 0.056989451307715114}. Best is trial 14 with value: 0.6658872614472943.\n",
      "[I 2023-10-12 15:39:08,221] Trial 21 finished with value: 0.6654368332985527 and parameters: {'max_depth': 8, 'colsample_bynode': 0.5012825966778762, 'reg_lambda': 3.2986277169793072, 'n_estimators': 327, 'learning_rate': 0.012374123394237012}. Best is trial 14 with value: 0.6658872614472943.\n",
      "[I 2023-10-12 15:41:44,982] Trial 22 finished with value: 0.6650698724118833 and parameters: {'max_depth': 9, 'colsample_bynode': 0.5323987876198109, 'reg_lambda': 3.228180243042226, 'n_estimators': 469, 'learning_rate': 0.010853943775816178}. Best is trial 14 with value: 0.6658872614472943.\n",
      "[I 2023-10-12 15:42:50,694] Trial 23 finished with value: 0.6638835303752167 and parameters: {'max_depth': 6, 'colsample_bynode': 0.5509991539730305, 'reg_lambda': 2.6624459862192085, 'n_estimators': 346, 'learning_rate': 0.054599468879921745}. Best is trial 14 with value: 0.6658872614472943.\n",
      "[I 2023-10-12 15:44:01,735] Trial 24 finished with value: 0.6635863795214736 and parameters: {'max_depth': 9, 'colsample_bynode': 0.52184966848753, 'reg_lambda': 3.647931991025738, 'n_estimators': 218, 'learning_rate': 0.032032001380391396}. Best is trial 14 with value: 0.6658872614472943.\n",
      "[I 2023-10-12 15:45:24,932] Trial 25 finished with value: 0.6627386722827258 and parameters: {'max_depth': 7, 'colsample_bynode': 0.562193713488327, 'reg_lambda': 3.1299880930400117, 'n_estimators': 359, 'learning_rate': 0.06052487666840106}. Best is trial 14 with value: 0.6658872614472943.\n",
      "[I 2023-10-12 15:46:43,400] Trial 26 finished with value: 0.6650025725975574 and parameters: {'max_depth': 8, 'colsample_bynode': 0.5018994611801878, 'reg_lambda': 3.529967934029115, 'n_estimators': 291, 'learning_rate': 0.027291177265059963}. Best is trial 14 with value: 0.6658872614472943.\n",
      "[I 2023-10-12 15:48:16,262] Trial 27 finished with value: 0.6600523682075735 and parameters: {'max_depth': 6, 'colsample_bynode': 0.52729017580172, 'reg_lambda': 3.8468001517073813, 'n_estimators': 475, 'learning_rate': 0.09001137008256328}. Best is trial 14 with value: 0.6658872614472943.\n",
      "[I 2023-10-12 15:48:50,655] Trial 28 finished with value: 0.6657882828004962 and parameters: {'max_depth': 5, 'colsample_bynode': 0.5959341588744784, 'reg_lambda': 3.0529166820083296, 'n_estimators': 197, 'learning_rate': 0.056123452368724}. Best is trial 14 with value: 0.6658872614472943.\n",
      "[I 2023-10-12 15:49:17,411] Trial 29 finished with value: 0.6668314724112155 and parameters: {'max_depth': 5, 'colsample_bynode': 0.5909090080377772, 'reg_lambda': 2.8233662584500996, 'n_estimators': 160, 'learning_rate': 0.04952229829814888}. Best is trial 29 with value: 0.6668314724112155.\n",
      "[I 2023-10-12 15:49:47,456] Trial 30 finished with value: 0.6666696467950529 and parameters: {'max_depth': 5, 'colsample_bynode': 0.591718850723601, 'reg_lambda': 2.6254171934628876, 'n_estimators': 158, 'learning_rate': 0.05423278107239954}. Best is trial 29 with value: 0.6668314724112155.\n",
      "[I 2023-10-12 15:50:14,448] Trial 31 finished with value: 0.666279812112536 and parameters: {'max_depth': 5, 'colsample_bynode': 0.5962725332110779, 'reg_lambda': 2.5508454795861013, 'n_estimators': 158, 'learning_rate': 0.05489073443735781}. Best is trial 29 with value: 0.6668314724112155.\n",
      "[I 2023-10-12 15:50:38,354] Trial 32 finished with value: 0.6662121439861031 and parameters: {'max_depth': 5, 'colsample_bynode': 0.5863045238072481, 'reg_lambda': 2.467193980578095, 'n_estimators': 135, 'learning_rate': 0.06788898354779141}. Best is trial 29 with value: 0.6668314724112155.\n",
      "[I 2023-10-12 15:51:01,192] Trial 33 finished with value: 0.6661561029952481 and parameters: {'max_depth': 5, 'colsample_bynode': 0.5911481317873412, 'reg_lambda': 2.4641847050806205, 'n_estimators': 135, 'learning_rate': 0.0967926464505107}. Best is trial 29 with value: 0.6668314724112155.\n",
      "[I 2023-10-12 15:51:25,703] Trial 34 finished with value: 0.6663803768242614 and parameters: {'max_depth': 5, 'colsample_bynode': 0.6077627274860719, 'reg_lambda': 2.2315136177699912, 'n_estimators': 140, 'learning_rate': 0.06979642792788754}. Best is trial 29 with value: 0.6668314724112155.\n",
      "[I 2023-10-12 15:52:04,064] Trial 35 finished with value: 0.6658024583850681 and parameters: {'max_depth': 6, 'colsample_bynode': 0.6136152490823429, 'reg_lambda': 1.819793850417684, 'n_estimators': 165, 'learning_rate': 0.04546187134571976}. Best is trial 29 with value: 0.6668314724112155.\n",
      "[I 2023-10-12 15:52:25,664] Trial 36 finished with value: 0.6671955674329582 and parameters: {'max_depth': 5, 'colsample_bynode': 0.6456616045114356, 'reg_lambda': 1.3644494601047512, 'n_estimators': 117, 'learning_rate': 0.04334999942547478}. Best is trial 36 with value: 0.6671955674329582.\n",
      "[I 2023-10-12 15:55:07,106] Trial 37 finished with value: 0.661449207164637 and parameters: {'max_depth': 6, 'colsample_bynode': 0.6483593213682803, 'reg_lambda': 1.377478546308339, 'n_estimators': 885, 'learning_rate': 0.040677165664574966}. Best is trial 36 with value: 0.6671955674329582.\n",
      "[I 2023-10-12 15:56:45,569] Trial 38 finished with value: 0.6580227363521767 and parameters: {'max_depth': 13, 'colsample_bynode': 0.6379811195560876, 'reg_lambda': 1.310384153928173, 'n_estimators': 233, 'learning_rate': 0.11740664372910789}. Best is trial 36 with value: 0.6671955674329582.\n",
      "[I 2023-10-12 15:56:59,080] Trial 39 finished with value: 0.6666225645608567 and parameters: {'max_depth': 5, 'colsample_bynode': 0.6157114581471568, 'reg_lambda': 1.1160640767407717, 'n_estimators': 95, 'learning_rate': 0.07298042203202343}. Best is trial 36 with value: 0.6671955674329582.\n",
      "[I 2023-10-12 15:57:11,042] Trial 40 finished with value: 0.6662709364905821 and parameters: {'max_depth': 5, 'colsample_bynode': 0.6287790426148797, 'reg_lambda': 0.8067013978701466, 'n_estimators': 85, 'learning_rate': 0.0901616876143255}. Best is trial 36 with value: 0.6671955674329582.\n",
      "[I 2023-10-12 15:57:26,893] Trial 41 finished with value: 0.6665231235150322 and parameters: {'max_depth': 5, 'colsample_bynode': 0.6112002745191835, 'reg_lambda': 1.7145038526678371, 'n_estimators': 99, 'learning_rate': 0.072859864398131}. Best is trial 36 with value: 0.6671955674329582.\n",
      "[I 2023-10-12 15:57:46,962] Trial 42 finished with value: 0.666871436067692 and parameters: {'max_depth': 6, 'colsample_bynode': 0.65982245069647, 'reg_lambda': 1.722962355985772, 'n_estimators': 97, 'learning_rate': 0.04319159390710614}. Best is trial 36 with value: 0.6671955674329582.\n",
      "[I 2023-10-12 15:58:20,164] Trial 43 finished with value: 0.6664972960823052 and parameters: {'max_depth': 6, 'colsample_bynode': 0.6647285553638419, 'reg_lambda': 1.0951049714688694, 'n_estimators': 185, 'learning_rate': 0.03722264655333436}. Best is trial 36 with value: 0.6671955674329582.\n",
      "[I 2023-10-12 15:58:37,559] Trial 44 finished with value: 0.6665010939753595 and parameters: {'max_depth': 6, 'colsample_bynode': 0.5747480323191538, 'reg_lambda': 1.731437064127888, 'n_estimators': 99, 'learning_rate': 0.046991271210544625}. Best is trial 36 with value: 0.6671955674329582.\n",
      "[I 2023-10-12 15:59:22,570] Trial 45 finished with value: 0.6635763643113161 and parameters: {'max_depth': 11, 'colsample_bynode': 0.6277489927071447, 'reg_lambda': 1.010027609370512, 'n_estimators': 109, 'learning_rate': 0.03674510627028807}. Best is trial 36 with value: 0.6671955674329582.\n",
      "[I 2023-10-12 16:00:18,070] Trial 46 finished with value: 0.6661627560610477 and parameters: {'max_depth': 5, 'colsample_bynode': 0.6507602012866983, 'reg_lambda': 0.5633917637110133, 'n_estimators': 400, 'learning_rate': 0.025379780192435062}. Best is trial 36 with value: 0.6671955674329582.\n",
      "[I 2023-10-12 16:03:09,726] Trial 47 finished with value: 0.6606688396211041 and parameters: {'max_depth': 6, 'colsample_bynode': 0.6684184305836737, 'reg_lambda': 1.5649735496933532, 'n_estimators': 994, 'learning_rate': 0.046299778475845196}. Best is trial 36 with value: 0.6671955674329582.\n",
      "[I 2023-10-12 16:03:19,522] Trial 48 finished with value: 0.6664468887862293 and parameters: {'max_depth': 5, 'colsample_bynode': 0.6391847263567781, 'reg_lambda': 1.9782729407534771, 'n_estimators': 51, 'learning_rate': 0.06830463028931918}. Best is trial 36 with value: 0.6671955674329582.\n",
      "[I 2023-10-12 16:04:05,001] Trial 49 finished with value: 0.6605312468958339 and parameters: {'max_depth': 6, 'colsample_bynode': 0.6040830382671947, 'reg_lambda': 2.857875893212531, 'n_estimators': 259, 'learning_rate': 0.1310749267681194}. Best is trial 36 with value: 0.6671955674329582.\n"
     ]
    }
   ],
   "source": [
    "K = 5   # Kfold 수\n",
    "opt_func = partial(optimizer, X=X, y=y, K=K)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\") # 최소/최대 어느 방향의 최적값을 구할 건지.\n",
    "study.optimize(opt_func, n_trials=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "72d0a118",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "72d0a118",
    "outputId": "978d6a99-5370-4b0e-c5f7-bb38fdde033b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    number     value             datetime_start          datetime_complete  \\\n0        0  0.657082 2023-10-12 14:56:42.777631 2023-10-12 14:57:20.619982   \n1        1  0.652428 2023-10-12 14:57:20.623046 2023-10-12 15:03:38.065175   \n2        2  0.661504 2023-10-12 15:03:38.067174 2023-10-12 15:04:55.716025   \n3        3  0.662883 2023-10-12 15:04:55.718025 2023-10-12 15:06:14.099310   \n4        4  0.660059 2023-10-12 15:06:14.101394 2023-10-12 15:07:11.762639   \n5        5  0.655964 2023-10-12 15:07:11.764781 2023-10-12 15:08:08.467280   \n6        6  0.657083 2023-10-12 15:08:08.468265 2023-10-12 15:12:22.803178   \n7        7  0.658763 2023-10-12 15:12:22.805187 2023-10-12 15:19:06.232013   \n8        8  0.653591 2023-10-12 15:19:06.233012 2023-10-12 15:23:11.328612   \n9        9  0.664886 2023-10-12 15:23:11.332062 2023-10-12 15:23:22.271343   \n10      10  0.655082 2023-10-12 15:23:22.273308 2023-10-12 15:24:43.122617   \n11      11  0.659150 2023-10-12 15:24:43.124619 2023-10-12 15:25:57.097633   \n12      12  0.664935 2023-10-12 15:25:57.100211 2023-10-12 15:26:12.479735   \n13      13  0.664055 2023-10-12 15:26:12.481733 2023-10-12 15:26:26.184013   \n14      14  0.665887 2023-10-12 15:26:26.185990 2023-10-12 15:27:25.228234   \n15      15  0.665422 2023-10-12 15:27:25.230159 2023-10-12 15:28:34.305374   \n16      16  0.659164 2023-10-12 15:28:34.306984 2023-10-12 15:30:22.593593   \n17      17  0.665339 2023-10-12 15:30:22.594593 2023-10-12 15:31:44.515518   \n18      18  0.658709 2023-10-12 15:31:44.517515 2023-10-12 15:34:26.742687   \n19      19  0.662467 2023-10-12 15:34:26.743687 2023-10-12 15:35:05.107034   \n20      20  0.658972 2023-10-12 15:35:05.108037 2023-10-12 15:37:33.659012   \n21      21  0.665437 2023-10-12 15:37:33.662269 2023-10-12 15:39:08.220484   \n22      22  0.665070 2023-10-12 15:39:08.223485 2023-10-12 15:41:44.981275   \n23      23  0.663884 2023-10-12 15:41:44.983271 2023-10-12 15:42:50.693671   \n24      24  0.663586 2023-10-12 15:42:50.696117 2023-10-12 15:44:01.735666   \n25      25  0.662739 2023-10-12 15:44:01.736652 2023-10-12 15:45:24.932959   \n26      26  0.665003 2023-10-12 15:45:24.934014 2023-10-12 15:46:43.400816   \n27      27  0.660052 2023-10-12 15:46:43.402951 2023-10-12 15:48:16.262428   \n28      28  0.665788 2023-10-12 15:48:16.264785 2023-10-12 15:48:50.654863   \n29      29  0.666831 2023-10-12 15:48:50.656864 2023-10-12 15:49:17.411803   \n30      30  0.666670 2023-10-12 15:49:17.412789 2023-10-12 15:49:47.456471   \n31      31  0.666280 2023-10-12 15:49:47.458268 2023-10-12 15:50:14.447535   \n32      32  0.666212 2023-10-12 15:50:14.449560 2023-10-12 15:50:38.354012   \n33      33  0.666156 2023-10-12 15:50:38.355033 2023-10-12 15:51:01.192111   \n34      34  0.666380 2023-10-12 15:51:01.193156 2023-10-12 15:51:25.702471   \n35      35  0.665802 2023-10-12 15:51:25.704480 2023-10-12 15:52:04.064632   \n36      36  0.667196 2023-10-12 15:52:04.065631 2023-10-12 15:52:25.664046   \n37      37  0.661449 2023-10-12 15:52:25.666046 2023-10-12 15:55:07.106855   \n38      38  0.658023 2023-10-12 15:55:07.107853 2023-10-12 15:56:45.569198   \n39      39  0.666623 2023-10-12 15:56:45.571170 2023-10-12 15:56:59.080252   \n40      40  0.666271 2023-10-12 15:56:59.081255 2023-10-12 15:57:11.041864   \n41      41  0.666523 2023-10-12 15:57:11.043862 2023-10-12 15:57:26.893538   \n42      42  0.666871 2023-10-12 15:57:26.895630 2023-10-12 15:57:46.962435   \n43      43  0.666497 2023-10-12 15:57:46.964458 2023-10-12 15:58:20.164425   \n44      44  0.666501 2023-10-12 15:58:20.165425 2023-10-12 15:58:37.559226   \n45      45  0.663576 2023-10-12 15:58:37.561226 2023-10-12 15:59:22.569139   \n46      46  0.666163 2023-10-12 15:59:22.571255 2023-10-12 16:00:18.070810   \n47      47  0.660669 2023-10-12 16:00:18.071813 2023-10-12 16:03:09.725390   \n48      48  0.666447 2023-10-12 16:03:09.728324 2023-10-12 16:03:19.521232   \n49      49  0.660531 2023-10-12 16:03:19.523231 2023-10-12 16:04:05.000241   \n\n                 duration  params_colsample_bynode  params_learning_rate  \\\n0  0 days 00:00:37.842351                 0.652781              0.221442   \n1  0 days 00:06:17.442129                 0.580784              0.217025   \n2  0 days 00:01:17.648851                 0.751779              0.043022   \n3  0 days 00:01:18.381285                 0.632793              0.036863   \n4  0 days 00:00:57.661245                 0.680095              0.136110   \n5  0 days 00:00:56.702499                 0.723493              0.251323   \n6  0 days 00:04:14.334913                 0.738288              0.115602   \n7  0 days 00:06:43.426826                 0.777936              0.035375   \n8  0 days 00:04:05.095600                 0.766420              0.247819   \n9  0 days 00:00:10.939281                 0.717500              0.196213   \n10 0 days 00:01:20.849309                 0.570395              0.298591   \n11 0 days 00:01:13.973014                 0.619611              0.081720   \n12 0 days 00:00:15.379524                 0.688934              0.010534   \n13 0 days 00:00:13.702280                 0.688021              0.169259   \n14 0 days 00:00:59.042244                 0.526432              0.013476   \n15 0 days 00:01:09.075215                 0.500010              0.016440   \n16 0 days 00:01:48.286609                 0.512568              0.080653   \n17 0 days 00:01:21.920925                 0.501067              0.013414   \n18 0 days 00:02:42.225172                 0.540655              0.073644   \n19 0 days 00:00:38.363347                 0.536321              0.107616   \n20 0 days 00:02:28.550975                 0.503916              0.056989   \n21 0 days 00:01:34.558215                 0.501283              0.012374   \n22 0 days 00:02:36.757790                 0.532399              0.010854   \n23 0 days 00:01:05.710400                 0.550999              0.054599   \n24 0 days 00:01:11.039549                 0.521850              0.032032   \n25 0 days 00:01:23.196307                 0.562194              0.060525   \n26 0 days 00:01:18.466802                 0.501899              0.027291   \n27 0 days 00:01:32.859477                 0.527290              0.090011   \n28 0 days 00:00:34.390078                 0.595934              0.056123   \n29 0 days 00:00:26.754939                 0.590909              0.049522   \n30 0 days 00:00:30.043682                 0.591719              0.054233   \n31 0 days 00:00:26.989267                 0.596273              0.054891   \n32 0 days 00:00:23.904452                 0.586305              0.067889   \n33 0 days 00:00:22.837078                 0.591148              0.096793   \n34 0 days 00:00:24.509315                 0.607763              0.069796   \n35 0 days 00:00:38.360152                 0.613615              0.045462   \n36 0 days 00:00:21.598415                 0.645662              0.043350   \n37 0 days 00:02:41.440809                 0.648359              0.040677   \n38 0 days 00:01:38.461345                 0.637981              0.117407   \n39 0 days 00:00:13.509082                 0.615711              0.072980   \n40 0 days 00:00:11.960609                 0.628779              0.090162   \n41 0 days 00:00:15.849676                 0.611200              0.072860   \n42 0 days 00:00:20.066805                 0.659822              0.043192   \n43 0 days 00:00:33.199967                 0.664729              0.037223   \n44 0 days 00:00:17.393801                 0.574748              0.046991   \n45 0 days 00:00:45.007913                 0.627749              0.036745   \n46 0 days 00:00:55.499555                 0.650760              0.025380   \n47 0 days 00:02:51.653577                 0.668418              0.046300   \n48 0 days 00:00:09.792908                 0.639185              0.068305   \n49 0 days 00:00:45.477010                 0.604083              0.131075   \n\n    params_max_depth  params_n_estimators  params_reg_lambda     state  \n0                 10                  118           4.123427  COMPLETE  \n1                 13                  966           0.580367  COMPLETE  \n2                 14                  104           1.490888  COMPLETE  \n3                 10                  203           4.565398  COMPLETE  \n4                  5                  353           4.198561  COMPLETE  \n5                 11                  128           2.107829  COMPLETE  \n6                 15                  407           4.058388  COMPLETE  \n7                 12                  784           3.760789  COMPLETE  \n8                 10                  621           3.897971  COMPLETE  \n9                  6                   50           2.174700  COMPLETE  \n10                 5                  544           2.933016  COMPLETE  \n11                 8                  280           2.971811  COMPLETE  \n12                 7                   55           4.610786  COMPLETE  \n13                 7                   52           4.934991  COMPLETE  \n14                 7                  254           3.402866  COMPLETE  \n15                 7                  300           3.383626  COMPLETE  \n16                 8                  447           3.328969  COMPLETE  \n17                 8                  291           3.320392  COMPLETE  \n18                 9                  587           3.484489  COMPLETE  \n19                 6                  216           2.674498  COMPLETE  \n20                 7                  698           3.639043  COMPLETE  \n21                 8                  327           3.298628  COMPLETE  \n22                 9                  469           3.228180  COMPLETE  \n23                 6                  346           2.662446  COMPLETE  \n24                 9                  218           3.647932  COMPLETE  \n25                 7                  359           3.129988  COMPLETE  \n26                 8                  291           3.529968  COMPLETE  \n27                 6                  475           3.846800  COMPLETE  \n28                 5                  197           3.052917  COMPLETE  \n29                 5                  160           2.823366  COMPLETE  \n30                 5                  158           2.625417  COMPLETE  \n31                 5                  158           2.550845  COMPLETE  \n32                 5                  135           2.467194  COMPLETE  \n33                 5                  135           2.464185  COMPLETE  \n34                 5                  140           2.231514  COMPLETE  \n35                 6                  165           1.819794  COMPLETE  \n36                 5                  117           1.364449  COMPLETE  \n37                 6                  885           1.377479  COMPLETE  \n38                13                  233           1.310384  COMPLETE  \n39                 5                   95           1.116064  COMPLETE  \n40                 5                   85           0.806701  COMPLETE  \n41                 5                   99           1.714504  COMPLETE  \n42                 6                   97           1.722962  COMPLETE  \n43                 6                  185           1.095105  COMPLETE  \n44                 6                   99           1.731437  COMPLETE  \n45                11                  109           1.010028  COMPLETE  \n46                 5                  400           0.563392  COMPLETE  \n47                 6                  994           1.564974  COMPLETE  \n48                 5                   51           1.978273  COMPLETE  \n49                 6                  259           2.857876  COMPLETE  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>number</th>\n      <th>value</th>\n      <th>datetime_start</th>\n      <th>datetime_complete</th>\n      <th>duration</th>\n      <th>params_colsample_bynode</th>\n      <th>params_learning_rate</th>\n      <th>params_max_depth</th>\n      <th>params_n_estimators</th>\n      <th>params_reg_lambda</th>\n      <th>state</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.657082</td>\n      <td>2023-10-12 14:56:42.777631</td>\n      <td>2023-10-12 14:57:20.619982</td>\n      <td>0 days 00:00:37.842351</td>\n      <td>0.652781</td>\n      <td>0.221442</td>\n      <td>10</td>\n      <td>118</td>\n      <td>4.123427</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.652428</td>\n      <td>2023-10-12 14:57:20.623046</td>\n      <td>2023-10-12 15:03:38.065175</td>\n      <td>0 days 00:06:17.442129</td>\n      <td>0.580784</td>\n      <td>0.217025</td>\n      <td>13</td>\n      <td>966</td>\n      <td>0.580367</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.661504</td>\n      <td>2023-10-12 15:03:38.067174</td>\n      <td>2023-10-12 15:04:55.716025</td>\n      <td>0 days 00:01:17.648851</td>\n      <td>0.751779</td>\n      <td>0.043022</td>\n      <td>14</td>\n      <td>104</td>\n      <td>1.490888</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.662883</td>\n      <td>2023-10-12 15:04:55.718025</td>\n      <td>2023-10-12 15:06:14.099310</td>\n      <td>0 days 00:01:18.381285</td>\n      <td>0.632793</td>\n      <td>0.036863</td>\n      <td>10</td>\n      <td>203</td>\n      <td>4.565398</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.660059</td>\n      <td>2023-10-12 15:06:14.101394</td>\n      <td>2023-10-12 15:07:11.762639</td>\n      <td>0 days 00:00:57.661245</td>\n      <td>0.680095</td>\n      <td>0.136110</td>\n      <td>5</td>\n      <td>353</td>\n      <td>4.198561</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>0.655964</td>\n      <td>2023-10-12 15:07:11.764781</td>\n      <td>2023-10-12 15:08:08.467280</td>\n      <td>0 days 00:00:56.702499</td>\n      <td>0.723493</td>\n      <td>0.251323</td>\n      <td>11</td>\n      <td>128</td>\n      <td>2.107829</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>0.657083</td>\n      <td>2023-10-12 15:08:08.468265</td>\n      <td>2023-10-12 15:12:22.803178</td>\n      <td>0 days 00:04:14.334913</td>\n      <td>0.738288</td>\n      <td>0.115602</td>\n      <td>15</td>\n      <td>407</td>\n      <td>4.058388</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>0.658763</td>\n      <td>2023-10-12 15:12:22.805187</td>\n      <td>2023-10-12 15:19:06.232013</td>\n      <td>0 days 00:06:43.426826</td>\n      <td>0.777936</td>\n      <td>0.035375</td>\n      <td>12</td>\n      <td>784</td>\n      <td>3.760789</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>0.653591</td>\n      <td>2023-10-12 15:19:06.233012</td>\n      <td>2023-10-12 15:23:11.328612</td>\n      <td>0 days 00:04:05.095600</td>\n      <td>0.766420</td>\n      <td>0.247819</td>\n      <td>10</td>\n      <td>621</td>\n      <td>3.897971</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>0.664886</td>\n      <td>2023-10-12 15:23:11.332062</td>\n      <td>2023-10-12 15:23:22.271343</td>\n      <td>0 days 00:00:10.939281</td>\n      <td>0.717500</td>\n      <td>0.196213</td>\n      <td>6</td>\n      <td>50</td>\n      <td>2.174700</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>0.655082</td>\n      <td>2023-10-12 15:23:22.273308</td>\n      <td>2023-10-12 15:24:43.122617</td>\n      <td>0 days 00:01:20.849309</td>\n      <td>0.570395</td>\n      <td>0.298591</td>\n      <td>5</td>\n      <td>544</td>\n      <td>2.933016</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>0.659150</td>\n      <td>2023-10-12 15:24:43.124619</td>\n      <td>2023-10-12 15:25:57.097633</td>\n      <td>0 days 00:01:13.973014</td>\n      <td>0.619611</td>\n      <td>0.081720</td>\n      <td>8</td>\n      <td>280</td>\n      <td>2.971811</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>0.664935</td>\n      <td>2023-10-12 15:25:57.100211</td>\n      <td>2023-10-12 15:26:12.479735</td>\n      <td>0 days 00:00:15.379524</td>\n      <td>0.688934</td>\n      <td>0.010534</td>\n      <td>7</td>\n      <td>55</td>\n      <td>4.610786</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>0.664055</td>\n      <td>2023-10-12 15:26:12.481733</td>\n      <td>2023-10-12 15:26:26.184013</td>\n      <td>0 days 00:00:13.702280</td>\n      <td>0.688021</td>\n      <td>0.169259</td>\n      <td>7</td>\n      <td>52</td>\n      <td>4.934991</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>0.665887</td>\n      <td>2023-10-12 15:26:26.185990</td>\n      <td>2023-10-12 15:27:25.228234</td>\n      <td>0 days 00:00:59.042244</td>\n      <td>0.526432</td>\n      <td>0.013476</td>\n      <td>7</td>\n      <td>254</td>\n      <td>3.402866</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>0.665422</td>\n      <td>2023-10-12 15:27:25.230159</td>\n      <td>2023-10-12 15:28:34.305374</td>\n      <td>0 days 00:01:09.075215</td>\n      <td>0.500010</td>\n      <td>0.016440</td>\n      <td>7</td>\n      <td>300</td>\n      <td>3.383626</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>0.659164</td>\n      <td>2023-10-12 15:28:34.306984</td>\n      <td>2023-10-12 15:30:22.593593</td>\n      <td>0 days 00:01:48.286609</td>\n      <td>0.512568</td>\n      <td>0.080653</td>\n      <td>8</td>\n      <td>447</td>\n      <td>3.328969</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>0.665339</td>\n      <td>2023-10-12 15:30:22.594593</td>\n      <td>2023-10-12 15:31:44.515518</td>\n      <td>0 days 00:01:21.920925</td>\n      <td>0.501067</td>\n      <td>0.013414</td>\n      <td>8</td>\n      <td>291</td>\n      <td>3.320392</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>0.658709</td>\n      <td>2023-10-12 15:31:44.517515</td>\n      <td>2023-10-12 15:34:26.742687</td>\n      <td>0 days 00:02:42.225172</td>\n      <td>0.540655</td>\n      <td>0.073644</td>\n      <td>9</td>\n      <td>587</td>\n      <td>3.484489</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19</td>\n      <td>0.662467</td>\n      <td>2023-10-12 15:34:26.743687</td>\n      <td>2023-10-12 15:35:05.107034</td>\n      <td>0 days 00:00:38.363347</td>\n      <td>0.536321</td>\n      <td>0.107616</td>\n      <td>6</td>\n      <td>216</td>\n      <td>2.674498</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>20</td>\n      <td>0.658972</td>\n      <td>2023-10-12 15:35:05.108037</td>\n      <td>2023-10-12 15:37:33.659012</td>\n      <td>0 days 00:02:28.550975</td>\n      <td>0.503916</td>\n      <td>0.056989</td>\n      <td>7</td>\n      <td>698</td>\n      <td>3.639043</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>21</td>\n      <td>0.665437</td>\n      <td>2023-10-12 15:37:33.662269</td>\n      <td>2023-10-12 15:39:08.220484</td>\n      <td>0 days 00:01:34.558215</td>\n      <td>0.501283</td>\n      <td>0.012374</td>\n      <td>8</td>\n      <td>327</td>\n      <td>3.298628</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>22</td>\n      <td>0.665070</td>\n      <td>2023-10-12 15:39:08.223485</td>\n      <td>2023-10-12 15:41:44.981275</td>\n      <td>0 days 00:02:36.757790</td>\n      <td>0.532399</td>\n      <td>0.010854</td>\n      <td>9</td>\n      <td>469</td>\n      <td>3.228180</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>23</td>\n      <td>0.663884</td>\n      <td>2023-10-12 15:41:44.983271</td>\n      <td>2023-10-12 15:42:50.693671</td>\n      <td>0 days 00:01:05.710400</td>\n      <td>0.550999</td>\n      <td>0.054599</td>\n      <td>6</td>\n      <td>346</td>\n      <td>2.662446</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>24</td>\n      <td>0.663586</td>\n      <td>2023-10-12 15:42:50.696117</td>\n      <td>2023-10-12 15:44:01.735666</td>\n      <td>0 days 00:01:11.039549</td>\n      <td>0.521850</td>\n      <td>0.032032</td>\n      <td>9</td>\n      <td>218</td>\n      <td>3.647932</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>25</td>\n      <td>0.662739</td>\n      <td>2023-10-12 15:44:01.736652</td>\n      <td>2023-10-12 15:45:24.932959</td>\n      <td>0 days 00:01:23.196307</td>\n      <td>0.562194</td>\n      <td>0.060525</td>\n      <td>7</td>\n      <td>359</td>\n      <td>3.129988</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>26</td>\n      <td>0.665003</td>\n      <td>2023-10-12 15:45:24.934014</td>\n      <td>2023-10-12 15:46:43.400816</td>\n      <td>0 days 00:01:18.466802</td>\n      <td>0.501899</td>\n      <td>0.027291</td>\n      <td>8</td>\n      <td>291</td>\n      <td>3.529968</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>27</td>\n      <td>0.660052</td>\n      <td>2023-10-12 15:46:43.402951</td>\n      <td>2023-10-12 15:48:16.262428</td>\n      <td>0 days 00:01:32.859477</td>\n      <td>0.527290</td>\n      <td>0.090011</td>\n      <td>6</td>\n      <td>475</td>\n      <td>3.846800</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>28</td>\n      <td>0.665788</td>\n      <td>2023-10-12 15:48:16.264785</td>\n      <td>2023-10-12 15:48:50.654863</td>\n      <td>0 days 00:00:34.390078</td>\n      <td>0.595934</td>\n      <td>0.056123</td>\n      <td>5</td>\n      <td>197</td>\n      <td>3.052917</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>29</td>\n      <td>0.666831</td>\n      <td>2023-10-12 15:48:50.656864</td>\n      <td>2023-10-12 15:49:17.411803</td>\n      <td>0 days 00:00:26.754939</td>\n      <td>0.590909</td>\n      <td>0.049522</td>\n      <td>5</td>\n      <td>160</td>\n      <td>2.823366</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>30</td>\n      <td>0.666670</td>\n      <td>2023-10-12 15:49:17.412789</td>\n      <td>2023-10-12 15:49:47.456471</td>\n      <td>0 days 00:00:30.043682</td>\n      <td>0.591719</td>\n      <td>0.054233</td>\n      <td>5</td>\n      <td>158</td>\n      <td>2.625417</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>31</td>\n      <td>0.666280</td>\n      <td>2023-10-12 15:49:47.458268</td>\n      <td>2023-10-12 15:50:14.447535</td>\n      <td>0 days 00:00:26.989267</td>\n      <td>0.596273</td>\n      <td>0.054891</td>\n      <td>5</td>\n      <td>158</td>\n      <td>2.550845</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>32</td>\n      <td>0.666212</td>\n      <td>2023-10-12 15:50:14.449560</td>\n      <td>2023-10-12 15:50:38.354012</td>\n      <td>0 days 00:00:23.904452</td>\n      <td>0.586305</td>\n      <td>0.067889</td>\n      <td>5</td>\n      <td>135</td>\n      <td>2.467194</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>33</td>\n      <td>0.666156</td>\n      <td>2023-10-12 15:50:38.355033</td>\n      <td>2023-10-12 15:51:01.192111</td>\n      <td>0 days 00:00:22.837078</td>\n      <td>0.591148</td>\n      <td>0.096793</td>\n      <td>5</td>\n      <td>135</td>\n      <td>2.464185</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>34</td>\n      <td>0.666380</td>\n      <td>2023-10-12 15:51:01.193156</td>\n      <td>2023-10-12 15:51:25.702471</td>\n      <td>0 days 00:00:24.509315</td>\n      <td>0.607763</td>\n      <td>0.069796</td>\n      <td>5</td>\n      <td>140</td>\n      <td>2.231514</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>35</td>\n      <td>0.665802</td>\n      <td>2023-10-12 15:51:25.704480</td>\n      <td>2023-10-12 15:52:04.064632</td>\n      <td>0 days 00:00:38.360152</td>\n      <td>0.613615</td>\n      <td>0.045462</td>\n      <td>6</td>\n      <td>165</td>\n      <td>1.819794</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>36</td>\n      <td>0.667196</td>\n      <td>2023-10-12 15:52:04.065631</td>\n      <td>2023-10-12 15:52:25.664046</td>\n      <td>0 days 00:00:21.598415</td>\n      <td>0.645662</td>\n      <td>0.043350</td>\n      <td>5</td>\n      <td>117</td>\n      <td>1.364449</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>37</td>\n      <td>0.661449</td>\n      <td>2023-10-12 15:52:25.666046</td>\n      <td>2023-10-12 15:55:07.106855</td>\n      <td>0 days 00:02:41.440809</td>\n      <td>0.648359</td>\n      <td>0.040677</td>\n      <td>6</td>\n      <td>885</td>\n      <td>1.377479</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>38</td>\n      <td>0.658023</td>\n      <td>2023-10-12 15:55:07.107853</td>\n      <td>2023-10-12 15:56:45.569198</td>\n      <td>0 days 00:01:38.461345</td>\n      <td>0.637981</td>\n      <td>0.117407</td>\n      <td>13</td>\n      <td>233</td>\n      <td>1.310384</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>39</td>\n      <td>0.666623</td>\n      <td>2023-10-12 15:56:45.571170</td>\n      <td>2023-10-12 15:56:59.080252</td>\n      <td>0 days 00:00:13.509082</td>\n      <td>0.615711</td>\n      <td>0.072980</td>\n      <td>5</td>\n      <td>95</td>\n      <td>1.116064</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>40</td>\n      <td>0.666271</td>\n      <td>2023-10-12 15:56:59.081255</td>\n      <td>2023-10-12 15:57:11.041864</td>\n      <td>0 days 00:00:11.960609</td>\n      <td>0.628779</td>\n      <td>0.090162</td>\n      <td>5</td>\n      <td>85</td>\n      <td>0.806701</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>41</td>\n      <td>0.666523</td>\n      <td>2023-10-12 15:57:11.043862</td>\n      <td>2023-10-12 15:57:26.893538</td>\n      <td>0 days 00:00:15.849676</td>\n      <td>0.611200</td>\n      <td>0.072860</td>\n      <td>5</td>\n      <td>99</td>\n      <td>1.714504</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>42</td>\n      <td>0.666871</td>\n      <td>2023-10-12 15:57:26.895630</td>\n      <td>2023-10-12 15:57:46.962435</td>\n      <td>0 days 00:00:20.066805</td>\n      <td>0.659822</td>\n      <td>0.043192</td>\n      <td>6</td>\n      <td>97</td>\n      <td>1.722962</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>43</td>\n      <td>0.666497</td>\n      <td>2023-10-12 15:57:46.964458</td>\n      <td>2023-10-12 15:58:20.164425</td>\n      <td>0 days 00:00:33.199967</td>\n      <td>0.664729</td>\n      <td>0.037223</td>\n      <td>6</td>\n      <td>185</td>\n      <td>1.095105</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>44</td>\n      <td>0.666501</td>\n      <td>2023-10-12 15:58:20.165425</td>\n      <td>2023-10-12 15:58:37.559226</td>\n      <td>0 days 00:00:17.393801</td>\n      <td>0.574748</td>\n      <td>0.046991</td>\n      <td>6</td>\n      <td>99</td>\n      <td>1.731437</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>45</td>\n      <td>0.663576</td>\n      <td>2023-10-12 15:58:37.561226</td>\n      <td>2023-10-12 15:59:22.569139</td>\n      <td>0 days 00:00:45.007913</td>\n      <td>0.627749</td>\n      <td>0.036745</td>\n      <td>11</td>\n      <td>109</td>\n      <td>1.010028</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>46</td>\n      <td>0.666163</td>\n      <td>2023-10-12 15:59:22.571255</td>\n      <td>2023-10-12 16:00:18.070810</td>\n      <td>0 days 00:00:55.499555</td>\n      <td>0.650760</td>\n      <td>0.025380</td>\n      <td>5</td>\n      <td>400</td>\n      <td>0.563392</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>47</td>\n      <td>0.660669</td>\n      <td>2023-10-12 16:00:18.071813</td>\n      <td>2023-10-12 16:03:09.725390</td>\n      <td>0 days 00:02:51.653577</td>\n      <td>0.668418</td>\n      <td>0.046300</td>\n      <td>6</td>\n      <td>994</td>\n      <td>1.564974</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>48</td>\n      <td>0.666447</td>\n      <td>2023-10-12 16:03:09.728324</td>\n      <td>2023-10-12 16:03:19.521232</td>\n      <td>0 days 00:00:09.792908</td>\n      <td>0.639185</td>\n      <td>0.068305</td>\n      <td>5</td>\n      <td>51</td>\n      <td>1.978273</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>49</td>\n      <td>0.660531</td>\n      <td>2023-10-12 16:03:19.523231</td>\n      <td>2023-10-12 16:04:05.000241</td>\n      <td>0 days 00:00:45.477010</td>\n      <td>0.604083</td>\n      <td>0.131075</td>\n      <td>6</td>\n      <td>259</td>\n      <td>2.857876</td>\n      <td>COMPLETE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optuna가 시도했던 모든 실험 관련 데이터\n",
    "study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a805da05",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a805da05",
    "outputId": "bcd1a494-0422-474c-d9e8-3e48cddef25a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.6672\n",
      "Best params:  {'max_depth': 5, 'colsample_bynode': 0.6456616045114356, 'reg_lambda': 1.3644494601047512, 'n_estimators': 117, 'learning_rate': 0.04334999942547478}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score: %.4f\" % study.best_value) # best score 출력\n",
    "print(\"Best params: \", study.best_trial.params) # best score일 때의 하이퍼파라미터들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "051ae1eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "051ae1eb",
    "outputId": "58266f06-c9df-4dde-cafa-6c5a921f85fe"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "File \u001B[1;32mc:\\users\\dukim\\workspace\\study\\stock\\algotrade\\venv\\lib\\site-packages\\optuna\\visualization\\_plotly_imports.py:7\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m try_import() \u001B[38;5;28;01mas\u001B[39;00m _imports:\n\u001B[1;32m----> 7\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mplotly\u001B[39;00m\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mplotly\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m __version__ \u001B[38;5;28;01mas\u001B[39;00m plotly_version\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'plotly'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[80], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# 실험 기록 시각화\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43moptuna\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvisualization\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mplot_optimization_history\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\dukim\\workspace\\study\\stock\\algotrade\\venv\\lib\\site-packages\\optuna\\visualization\\_optimization_history.py:222\u001B[0m, in \u001B[0;36mplot_optimization_history\u001B[1;34m(study, target, target_name, error_bar)\u001B[0m\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mplot_optimization_history\u001B[39m(\n\u001B[0;32m    173\u001B[0m     study: Study \u001B[38;5;241m|\u001B[39m Sequence[Study],\n\u001B[0;32m    174\u001B[0m     \u001B[38;5;241m*\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    177\u001B[0m     error_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    178\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgo.Figure\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    179\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Plot optimization history of all trials in a study.\u001B[39;00m\n\u001B[0;32m    180\u001B[0m \n\u001B[0;32m    181\u001B[0m \u001B[38;5;124;03m    Example:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    219\u001B[0m \u001B[38;5;124;03m        A :class:`plotly.graph_objs.Figure` object.\u001B[39;00m\n\u001B[0;32m    220\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 222\u001B[0m     \u001B[43m_imports\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheck\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    224\u001B[0m     info_list \u001B[38;5;241m=\u001B[39m _get_optimization_history_info_list(study, target, target_name, error_bar)\n\u001B[0;32m    225\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _get_optimization_history_plot(info_list, target_name)\n",
      "File \u001B[1;32mc:\\users\\dukim\\workspace\\study\\stock\\algotrade\\venv\\lib\\site-packages\\optuna\\_imports.py:89\u001B[0m, in \u001B[0;36m_DeferredImportExceptionContextManager.check\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     87\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_deferred \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     88\u001B[0m     exc_value, message \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_deferred\n\u001B[1;32m---> 89\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(message) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mexc_value\u001B[39;00m\n",
      "\u001B[1;31mImportError\u001B[0m: Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'."
     ]
    }
   ],
   "source": [
    "# 실험 기록 시각화\n",
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "efbf8f65",
   "metadata": {
    "scrolled": false,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "efbf8f65",
    "outputId": "7368048b-ad41-45ef-9350-cf7a16da295b"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "File \u001B[1;32mc:\\users\\dukim\\workspace\\study\\stock\\algotrade\\venv\\lib\\site-packages\\optuna\\visualization\\_plotly_imports.py:7\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m try_import() \u001B[38;5;28;01mas\u001B[39;00m _imports:\n\u001B[1;32m----> 7\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mplotly\u001B[39;00m\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mplotly\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m __version__ \u001B[38;5;28;01mas\u001B[39;00m plotly_version\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'plotly'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[81], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# hyper-parameter들의 중요도\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43moptuna\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvisualization\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mplot_param_importances\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\dukim\\workspace\\study\\stock\\algotrade\\venv\\lib\\site-packages\\optuna\\visualization\\_param_importances.py:137\u001B[0m, in \u001B[0;36mplot_param_importances\u001B[1;34m(study, evaluator, params, target, target_name)\u001B[0m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mplot_param_importances\u001B[39m(\n\u001B[0;32m     74\u001B[0m     study: Study,\n\u001B[0;32m     75\u001B[0m     evaluator: BaseImportanceEvaluator \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     79\u001B[0m     target_name: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mObjective Value\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     80\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgo.Figure\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m     81\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Plot hyperparameter importances.\u001B[39;00m\n\u001B[0;32m     82\u001B[0m \n\u001B[0;32m     83\u001B[0m \u001B[38;5;124;03m    Example:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    134\u001B[0m \u001B[38;5;124;03m        A :class:`plotly.graph_objs.Figure` object.\u001B[39;00m\n\u001B[0;32m    135\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 137\u001B[0m     \u001B[43m_imports\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheck\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    139\u001B[0m     importances_info \u001B[38;5;241m=\u001B[39m _get_importances_info(study, evaluator, params, target, target_name)\n\u001B[0;32m    140\u001B[0m     hover_template \u001B[38;5;241m=\u001B[39m _get_hover_template(importances_info, study)\n",
      "File \u001B[1;32mc:\\users\\dukim\\workspace\\study\\stock\\algotrade\\venv\\lib\\site-packages\\optuna\\_imports.py:89\u001B[0m, in \u001B[0;36m_DeferredImportExceptionContextManager.check\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     87\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_deferred \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     88\u001B[0m     exc_value, message \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_deferred\n\u001B[1;32m---> 89\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(message) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mexc_value\u001B[39;00m\n",
      "\u001B[1;31mImportError\u001B[0m: Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'."
     ]
    }
   ],
   "source": [
    "# hyper-parameter들의 중요도\n",
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b360ec",
   "metadata": {
    "id": "24b360ec"
   },
   "source": [
    "### 7. 테스트 및 제출 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Make KFold OOF prediction\n",
    "def oof_preds(best_model):\n",
    "\n",
    "    # make KFold\n",
    "    folds = StratifiedKFold(n_splits=K, random_state=42, shuffle=True)\n",
    "    final_preds = []\n",
    "    losses = []\n",
    "    # fitting with best_model\n",
    "    for i, (train_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "        X_train = X.iloc[train_idx, :]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        X_val = X.iloc[val_idx, :]\n",
    "        y_val = y.iloc[val_idx]\n",
    "\n",
    "        print(f\"========== Fold {i+1} ==========\")\n",
    "        best_model.fit(X_train, y_train)\n",
    "        preds = best_model.predict_proba(X_val)[:, 1]\n",
    "        test_preds = best_model.predict_proba(test)[:, 1]\n",
    "        final_preds.append(test_preds)\n",
    "        loss = evaluation_metric(y_val, preds)\n",
    "\n",
    "        losses.append(loss)\n",
    "\n",
    "    avg_loss = np.mean(losses)\n",
    "    print(f\"Loss : {avg_loss:.4f}\")\n",
    "    return final_preds"
   ],
   "metadata": {
    "id": "vbGPA_pvtJXf"
   },
   "id": "vbGPA_pvtJXf",
   "execution_count": 88,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test.info() # 결측치 없음."
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xWEElxsC7Gfl",
    "outputId": "f9f39b1c-fde5-47e7-e5b1-bbc0094e9cb0"
   },
   "id": "xWEElxsC7Gfl",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 67842 entries, 0 to 67841\n",
      "Data columns (total 22 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 67842 non-null  int64  \n",
      " 1   loc                67842 non-null  float64\n",
      " 2   v(g)               67842 non-null  float64\n",
      " 3   ev(g)              67842 non-null  float64\n",
      " 4   iv(g)              67842 non-null  float64\n",
      " 5   n                  67842 non-null  float64\n",
      " 6   v                  67842 non-null  float64\n",
      " 7   l                  67842 non-null  float64\n",
      " 8   d                  67842 non-null  float64\n",
      " 9   i                  67842 non-null  float64\n",
      " 10  e                  67842 non-null  float64\n",
      " 11  b                  67842 non-null  float64\n",
      " 12  t                  67842 non-null  float64\n",
      " 13  lOCode             67842 non-null  int64  \n",
      " 14  lOComment          67842 non-null  int64  \n",
      " 15  lOBlank            67842 non-null  int64  \n",
      " 16  locCodeAndComment  67842 non-null  int64  \n",
      " 17  uniq_Op            67842 non-null  float64\n",
      " 18  uniq_Opnd          67842 non-null  float64\n",
      " 19  total_Op           67842 non-null  float64\n",
      " 20  total_Opnd         67842 non-null  float64\n",
      " 21  branchCount        67842 non-null  float64\n",
      "dtypes: float64(17), int64(5)\n",
      "memory usage: 11.4 MB\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b6787765",
   "metadata": {
    "id": "b6787765",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "outputId": "2876cc07-2f84-46b9-a06f-8058a88c1c59"
   },
   "outputs": [],
   "source": [
    "## X_test 만들기 : 앞서했던 전처리를 동일하게 적용해주면 됨.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a0daf54e",
   "metadata": {
    "id": "a0daf54e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "90168fcf-9c4d-4a37-a83c-45ed45ba9997"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Fold 1 ==========\n",
      "========== Fold 2 ==========\n",
      "========== Fold 3 ==========\n",
      "========== Fold 4 ==========\n",
      "========== Fold 5 ==========\n",
      "Loss : 0.7919\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([0.26644674, 0.23265156, 0.6457157 , ..., 0.20588079, 0.11557309,\n       0.7869202 ], dtype=float32)"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = study.best_trial.params\n",
    "\n",
    "# define best model\n",
    "best_model = XGBClassifier(**best_params,\n",
    "                           random_state=61)\n",
    "\n",
    "# model finalization : 가장 일반적으로 좋은 예측 성능을 냈던 모델로, 전체 데이터 트레이닝.\n",
    "\n",
    "preds = oof_preds(best_model)\n",
    "preds = np.mean(preds, axis=0)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8ff2070c",
   "metadata": {
    "id": "8ff2070c"
   },
   "outputs": [],
   "source": [
    "submission['defects'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "55a2c13f",
   "metadata": {
    "id": "55a2c13f"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(base_path+\"submission_xgboost_kfold.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "QIgSFAdJ8oRh"
   },
   "id": "QIgSFAdJ8oRh",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}