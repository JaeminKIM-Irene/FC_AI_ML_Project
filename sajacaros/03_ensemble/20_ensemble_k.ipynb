{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# 각 알고리즘 별 oof를 수집하여 Ridge를 이용하여 weight를 추출\n",
    "# Voting model을 구성하여 위에서 구한 weight기반하여 결과 추출"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import FunctionTransformer, PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data_path='../../data/'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "ambrosm_oof_df = pd.read_csv(data_path+'oof/ambrosm.csv')\n",
    "lightgbm_oof_df = pd.read_csv(data_path+'oof/lightgbm.csv')\n",
    "xgboost_oof_df = pd.read_csv(data_path+'oof/xgboost.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(base_path + 'train.csv', index_col='id')\n",
    "# test_df = pd.read_csv(base_path + 'test.csv', index_col='id')\n",
    "train_df = pd.read_csv(data_path + 'train_f1.csv', index_col='id')\n",
    "test_df = pd.read_csv(data_path + 'test_f1.csv', index_col='id')\n",
    "submission_df = pd.read_csv(data_path + 'sample_submission.csv', index_col='id')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "X = train_df.drop(columns='defects')\n",
    "y = train_df['defects']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "models = {\n",
    "    'xgboost': XGBClassifier(\n",
    "        max_depth=5,\n",
    "        colsample_bynode=0.5195981912942003,\n",
    "        reg_lambda=2.0596502472632006,\n",
    "        n_estimators=1345,\n",
    "        learning_rate=0.010119804013091233,\n",
    "        random_state=61,\n",
    "    ),\n",
    "    'lightgbm': LGBMClassifier(\n",
    "        max_depth=22,\n",
    "        num_leaves=128,\n",
    "        min_child_samples=46,\n",
    "        colsample_bytree=0.5924502637788397,\n",
    "        n_estimators=659,\n",
    "        learning_rate=0.008200284931836449,\n",
    "        random_state=61,\n",
    "    ),\n",
    "    'rf':RandomForestClassifier(min_samples_leaf=220, max_features=1.0, random_state=61),\n",
    "    'hgb':HistGradientBoostingClassifier(random_state=61),\n",
    "    'logistic_nystroem': make_pipeline(\n",
    "        FunctionTransformer(np.log1p),\n",
    "        Nystroem(n_components=400, random_state=61),\n",
    "        StandardScaler(),\n",
    "        LogisticRegression(dual=False, C=0.0032, max_iter=1500, random_state=61)\n",
    "    ),\n",
    "    'extra': make_pipeline(\n",
    "        FunctionTransformer(np.log1p),\n",
    "        ExtraTreesClassifier(\n",
    "            n_estimators=100,\n",
    "            min_samples_leaf=110,\n",
    "            max_features=1.0,\n",
    "            random_state=61\n",
    "        ),\n",
    "    ),\n",
    "    'poly': make_pipeline(\n",
    "        FunctionTransformer(np.log1p),\n",
    "        PolynomialFeatures(2, include_bias=False),\n",
    "        StandardScaler(),\n",
    "        LogisticRegression(\n",
    "            dual=False,\n",
    "            C=0.32,\n",
    "            class_weight='balanced',\n",
    "            max_iter=1500,\n",
    "            random_state=61,\n",
    "            solver='newton-cholesky'\n",
    "        )\n",
    "    ),\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Make KFold OOF prediction\n",
    "K=5\n",
    "def oof_preds(best_model, model_name=None):\n",
    "    if model_name:\n",
    "        print(f\"{model_name}'s oof prediction\")\n",
    "\n",
    "    # make KFold\n",
    "    folds = StratifiedKFold(n_splits=K, random_state=61, shuffle=True)\n",
    "    final_preds = []\n",
    "    losses = []\n",
    "    oof = np.full(len(X), np.nan)\n",
    "    # fitting with best_model\n",
    "    for i, (train_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "        X_train = X.iloc[train_idx, :]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        X_val = X.iloc[val_idx, :]\n",
    "        y_val = y.iloc[val_idx]\n",
    "\n",
    "        print(f\"========== Fold {i+1} ==========\")\n",
    "        best_model.fit(X_train, y_train)\n",
    "        preds = best_model.predict_proba(X_val)[:, 1]\n",
    "        oof[val_idx] = preds\n",
    "        test_preds = best_model.predict_proba(test_df)[:, 1]\n",
    "        final_preds.append(test_preds)\n",
    "        loss = roc_auc_score(y_val, preds)\n",
    "\n",
    "        losses.append(loss)\n",
    "\n",
    "    avg_loss = np.mean(losses)\n",
    "    print(f\"Loss : {avg_loss:.4f}\")\n",
    "    return final_preds, oof, avg_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost's oof prediction\n",
      "========== Fold 1 ==========\n",
      "========== Fold 2 ==========\n",
      "========== Fold 3 ==========\n",
      "========== Fold 4 ==========\n",
      "========== Fold 5 ==========\n",
      "Loss : 0.7923\n",
      "lightgbm's oof prediction\n",
      "========== Fold 1 ==========\n",
      "========== Fold 2 ==========\n",
      "========== Fold 3 ==========\n",
      "========== Fold 4 ==========\n",
      "========== Fold 5 ==========\n",
      "Loss : 0.7911\n",
      "rf's oof prediction\n",
      "========== Fold 1 ==========\n",
      "========== Fold 2 ==========\n",
      "========== Fold 3 ==========\n",
      "========== Fold 4 ==========\n",
      "========== Fold 5 ==========\n",
      "Loss : 0.7911\n",
      "hgb's oof prediction\n",
      "========== Fold 1 ==========\n",
      "========== Fold 2 ==========\n",
      "========== Fold 3 ==========\n",
      "========== Fold 4 ==========\n",
      "========== Fold 5 ==========\n",
      "Loss : 0.7914\n",
      "logistic_nystroem's oof prediction\n",
      "========== Fold 1 ==========\n",
      "========== Fold 2 ==========\n",
      "========== Fold 3 ==========\n",
      "========== Fold 4 ==========\n",
      "========== Fold 5 ==========\n",
      "Loss : 0.7911\n",
      "extra's oof prediction\n",
      "========== Fold 1 ==========\n",
      "========== Fold 2 ==========\n",
      "========== Fold 3 ==========\n",
      "========== Fold 4 ==========\n",
      "========== Fold 5 ==========\n",
      "Loss : 0.7914\n",
      "poly's oof prediction\n",
      "========== Fold 1 ==========\n",
      "========== Fold 2 ==========\n",
      "========== Fold 3 ==========\n",
      "========== Fold 4 ==========\n",
      "========== Fold 5 ==========\n",
      "Loss : 0.7896\n"
     ]
    }
   ],
   "source": [
    "model_scores = [(model_name, oof_preds(model, model_name)[2]) for model_name, model in models.items()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "[('xgboost', 0.7922969635583282),\n ('hgb', 0.7914157169781412),\n ('extra', 0.7914027736506613),\n ('rf', 0.7911496027838701),\n ('lightgbm', 0.7911350332082578),\n ('logistic_nystroem', 0.7911317840722252),\n ('poly', 0.7896454270506789)]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores.sort(key=lambda m: m[1], reverse=True)\n",
    "model_scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "def run_k_fold(models, model_scores, num=6, weight='auto'):\n",
    "    start = 2\n",
    "    if weight=='auto':\n",
    "        weights = [6,5,4,3,2,1]\n",
    "    elif weight=='balance':\n",
    "        weights = [1]*num\n",
    "    else:\n",
    "        weights = [6,5,4,3,2,1]\n",
    "    best_score = 0\n",
    "    best_model_num = 0\n",
    "    for model_num in range(start, start+num-1):\n",
    "\n",
    "        chosen_models = [(model_scores[m_idx][0], models[model_scores[m_idx][0]]) for m_idx in range(model_num)]\n",
    "        chosen_model_names = [model_scores[m_idx][0] for m_idx in range(model_num)]\n",
    "        print(f'chosen models : {chosen_model_names}')\n",
    "        voter_model = VotingClassifier(chosen_models, weights = weights[:model_num], voting = 'soft')\n",
    "        preds, oof, oof_score = oof_preds(voter_model)\n",
    "        preds = np.mean(preds, axis=0)\n",
    "        if model_num==2 or best_score<oof_score:\n",
    "            best_preds = preds\n",
    "            best_score = oof_score\n",
    "            best_model_num = model_num\n",
    "    print(f'best model 개수 : {best_model_num}, best oof score : {best_score}')\n",
    "    return best_model_num, best_score, best_preds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen models : ['xgboost', 'hgb']\n",
      "========== Fold 1 ==========\n",
      "========== Fold 2 ==========\n",
      "========== Fold 3 ==========\n",
      "========== Fold 4 ==========\n",
      "========== Fold 5 ==========\n",
      "Loss : 0.7922\n",
      "chosen models : ['xgboost', 'hgb', 'extra']\n",
      "========== Fold 1 ==========\n",
      "========== Fold 2 ==========\n",
      "========== Fold 3 ==========\n",
      "========== Fold 4 ==========\n",
      "========== Fold 5 ==========\n",
      "Loss : 0.7924\n",
      "chosen models : ['xgboost', 'hgb', 'extra', 'rf']\n",
      "========== Fold 1 ==========\n",
      "========== Fold 2 ==========\n",
      "========== Fold 3 ==========\n",
      "========== Fold 4 ==========\n",
      "========== Fold 5 ==========\n",
      "Loss : 0.7923\n",
      "chosen models : ['xgboost', 'hgb', 'extra', 'rf', 'lightgbm']\n",
      "========== Fold 1 ==========\n",
      "========== Fold 2 ==========\n",
      "========== Fold 3 ==========\n",
      "========== Fold 4 ==========\n",
      "========== Fold 5 ==========\n",
      "Loss : 0.7924\n",
      "chosen models : ['xgboost', 'hgb', 'extra', 'rf', 'lightgbm', 'logistic_nystroem']\n",
      "========== Fold 1 ==========\n",
      "========== Fold 2 ==========\n",
      "========== Fold 3 ==========\n",
      "========== Fold 4 ==========\n",
      "========== Fold 5 ==========\n",
      "Loss : 0.7927\n",
      "chosen models : ['xgboost', 'hgb', 'extra', 'rf', 'lightgbm', 'logistic_nystroem', 'poly']\n",
      "========== Fold 1 ==========\n",
      "========== Fold 2 ==========\n",
      "========== Fold 3 ==========\n",
      "========== Fold 4 ==========\n",
      "========== Fold 5 ==========\n",
      "Loss : 0.7926\n",
      "best model 개수 : 6, best oof score : 0.7926516101929101\n"
     ]
    }
   ],
   "source": [
    "_,_,best_preds = run_k_fold(models, model_scores, num=7, weight='balance')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "submission_df['defects'] = best_preds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "submission_df.to_csv(data_path+'submission/ensemble_selected_balance.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}