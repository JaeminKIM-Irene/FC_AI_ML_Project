{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# 각 알고리즘 별 oof를 수집하여 Ridge를 이용하여 weight를 추출\n",
    "# Voting model을 구성하여 위에서 구한 weight기반하여 결과 추출"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import FunctionTransformer, PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "data_path='../../data/'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "ambrosm_oof_df = pd.read_csv(data_path+'oof/ambrosm.csv')\n",
    "lightgbm_oof_df = pd.read_csv(data_path+'oof/lightgbm.csv')\n",
    "xgboost_oof_df = pd.read_csv(data_path+'oof/xgboost.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(data_path+'train.csv', index_col='id')\n",
    "test_df = pd.read_csv(data_path+'test.csv', index_col='id')\n",
    "submission_df = pd.read_csv(data_path+'sample_submission.csv', index_col='id')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "X = train_df.drop(columns='defects')\n",
    "y = train_df['defects']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "        linear_best_oof  logistic_best_oof  logistic_nystroem_best_oof  \\\n0              0.113020           0.292676                    0.263026   \n1              0.091172           0.217814                    0.191553   \n2              0.077846           0.177005                    0.161153   \n3              0.083293           0.187400                    0.159725   \n4              0.091548           0.231135                    0.313546   \n...                 ...                ...                         ...   \n101758         0.082243           0.180461                    0.160814   \n101759         0.151209           0.397482                    0.467674   \n101760         0.113829           0.317497                    0.338628   \n101761         0.078646           0.178350                    0.164692   \n101762         0.539356           0.794604                    0.832561   \n\n        extra_best_oof  rf_best_oof  knn_best_oof  hgb_best_oof  xgboost_oof  \\\n0             0.087506     0.082296      0.077995      0.084565     0.071362   \n1             0.065491     0.060955      0.059274      0.057399     0.053843   \n2             0.046353     0.038370      0.057778      0.073632     0.045884   \n3             0.086816     0.075404      0.066361      0.082444     0.085829   \n4             0.125164     0.136323      0.116845      0.097831     0.112108   \n...                ...          ...           ...           ...          ...   \n101758        0.056628     0.046545      0.076260      0.053516     0.078027   \n101759        0.184923     0.187295      0.196183      0.183232     0.166571   \n101760        0.155416     0.148849      0.127197      0.125833     0.143557   \n101761        0.053035     0.048034      0.055675      0.050798     0.062254   \n101762        0.609086     0.598266      0.508593      0.573442     0.568581   \n\n        lightgbm_oof  \n0           0.074083  \n1           0.055853  \n2           0.049316  \n3           0.080914  \n4           0.104143  \n...              ...  \n101758      0.052296  \n101759      0.193487  \n101760      0.126170  \n101761      0.046861  \n101762      0.554169  \n\n[101763 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>linear_best_oof</th>\n      <th>logistic_best_oof</th>\n      <th>logistic_nystroem_best_oof</th>\n      <th>extra_best_oof</th>\n      <th>rf_best_oof</th>\n      <th>knn_best_oof</th>\n      <th>hgb_best_oof</th>\n      <th>xgboost_oof</th>\n      <th>lightgbm_oof</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.113020</td>\n      <td>0.292676</td>\n      <td>0.263026</td>\n      <td>0.087506</td>\n      <td>0.082296</td>\n      <td>0.077995</td>\n      <td>0.084565</td>\n      <td>0.071362</td>\n      <td>0.074083</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.091172</td>\n      <td>0.217814</td>\n      <td>0.191553</td>\n      <td>0.065491</td>\n      <td>0.060955</td>\n      <td>0.059274</td>\n      <td>0.057399</td>\n      <td>0.053843</td>\n      <td>0.055853</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.077846</td>\n      <td>0.177005</td>\n      <td>0.161153</td>\n      <td>0.046353</td>\n      <td>0.038370</td>\n      <td>0.057778</td>\n      <td>0.073632</td>\n      <td>0.045884</td>\n      <td>0.049316</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.083293</td>\n      <td>0.187400</td>\n      <td>0.159725</td>\n      <td>0.086816</td>\n      <td>0.075404</td>\n      <td>0.066361</td>\n      <td>0.082444</td>\n      <td>0.085829</td>\n      <td>0.080914</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.091548</td>\n      <td>0.231135</td>\n      <td>0.313546</td>\n      <td>0.125164</td>\n      <td>0.136323</td>\n      <td>0.116845</td>\n      <td>0.097831</td>\n      <td>0.112108</td>\n      <td>0.104143</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>101758</th>\n      <td>0.082243</td>\n      <td>0.180461</td>\n      <td>0.160814</td>\n      <td>0.056628</td>\n      <td>0.046545</td>\n      <td>0.076260</td>\n      <td>0.053516</td>\n      <td>0.078027</td>\n      <td>0.052296</td>\n    </tr>\n    <tr>\n      <th>101759</th>\n      <td>0.151209</td>\n      <td>0.397482</td>\n      <td>0.467674</td>\n      <td>0.184923</td>\n      <td>0.187295</td>\n      <td>0.196183</td>\n      <td>0.183232</td>\n      <td>0.166571</td>\n      <td>0.193487</td>\n    </tr>\n    <tr>\n      <th>101760</th>\n      <td>0.113829</td>\n      <td>0.317497</td>\n      <td>0.338628</td>\n      <td>0.155416</td>\n      <td>0.148849</td>\n      <td>0.127197</td>\n      <td>0.125833</td>\n      <td>0.143557</td>\n      <td>0.126170</td>\n    </tr>\n    <tr>\n      <th>101761</th>\n      <td>0.078646</td>\n      <td>0.178350</td>\n      <td>0.164692</td>\n      <td>0.053035</td>\n      <td>0.048034</td>\n      <td>0.055675</td>\n      <td>0.050798</td>\n      <td>0.062254</td>\n      <td>0.046861</td>\n    </tr>\n    <tr>\n      <th>101762</th>\n      <td>0.539356</td>\n      <td>0.794604</td>\n      <td>0.832561</td>\n      <td>0.609086</td>\n      <td>0.598266</td>\n      <td>0.508593</td>\n      <td>0.573442</td>\n      <td>0.568581</td>\n      <td>0.554169</td>\n    </tr>\n  </tbody>\n</table>\n<p>101763 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_oof_df = pd.concat([ambrosm_oof_df, xgboost_oof_df, lightgbm_oof_df], axis=1)\n",
    "all_oof_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha : 1e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": "linear_best_oof              -1.338477\nlogistic_best_oof            -1.932318\nlogistic_nystroem_best_oof   -2.560529\nextra_best_oof                2.199417\nrf_best_oof                   0.459820\nknn_best_oof                  1.566002\nhgb_best_oof                  0.894229\nxgboost_oof                   1.590566\nlightgbm_oof                  1.191794\ndtype: float64"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "ridge_model = RidgeClassifierCV(alphas=np.logspace(-5, 1, 10), fit_intercept=False, scoring='roc_auc', cv=5)\n",
    "ridge_model.fit(all_oof_df, y)\n",
    "weights = ridge_model.coef_[0]\n",
    "print(f'best alpha : {ridge_model.alpha_}')\n",
    "pd.Series(weights, index=all_oof_df.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('linear',make_pipeline(\n",
    "                FunctionTransformer(np.log1p),\n",
    "                PolynomialFeatures(2, include_bias=False),\n",
    "                StandardScaler(),\n",
    "                CalibratedClassifierCV(LinearSVC(dual=False, C=0.78858))\n",
    "            )),\n",
    "    ('logistic',make_pipeline(\n",
    "                FunctionTransformer(np.log1p),\n",
    "                PolynomialFeatures(2, include_bias=False),\n",
    "                StandardScaler(),\n",
    "                LogisticRegression(\n",
    "                    dual=False,\n",
    "                    C=0.32,\n",
    "                    class_weight='balanced',\n",
    "                    max_iter=1500,\n",
    "                    random_state=61,\n",
    "                    solver='newton-cholesky'\n",
    "                )\n",
    "            )),\n",
    "    ('logistic_nystroem',make_pipeline(\n",
    "                FunctionTransformer(np.log1p),\n",
    "                Nystroem(n_components=400, random_state=61),\n",
    "                StandardScaler(),\n",
    "                LogisticRegression(dual=False, C=0.0032, max_iter=1500, random_state=61)\n",
    "            )),\n",
    "    ('extra',make_pipeline(\n",
    "                FunctionTransformer(np.log1p),\n",
    "                ExtraTreesClassifier(\n",
    "                    n_estimators=100,\n",
    "                    min_samples_leaf=110,\n",
    "                    max_features=1.0,\n",
    "                    random_state=61\n",
    "                ),\n",
    "            )),\n",
    "    ('rf',RandomForestClassifier(min_samples_leaf=220, max_features=1.0, random_state=61)),\n",
    "    ('knn',make_pipeline(\n",
    "                FunctionTransformer(np.log1p),\n",
    "                StandardScaler(),\n",
    "                KNeighborsClassifier(\n",
    "                    n_neighbors=360,\n",
    "                    weights='distance'\n",
    "                )\n",
    "            )),\n",
    "    ('hgb',HistGradientBoostingClassifier(random_state=61)),\n",
    "    ('xgboost',XGBClassifier(\n",
    "            max_depth=5,\n",
    "            colsample_bynode=0.6028784042231218,\n",
    "            reg_lambda=1.9107959408881667,\n",
    "            n_estimators=38,\n",
    "            learning_rate=0.19089614460186538,\n",
    "            random_state=61,\n",
    "            eval_metric=roc_auc_score,\n",
    "        )\n",
    "    ),\n",
    "    ('lightgbm',LGBMClassifier(\n",
    "            max_depth=24,\n",
    "            num_leaves=32,\n",
    "            min_child_samples=74,\n",
    "            colsample_bytree=0.7080352104708246,\n",
    "            n_estimators=63,\n",
    "            learning_rate=0.09089244698723227,\n",
    "            random_state=61\n",
    "        )\n",
    "    )\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Make KFold OOF prediction\n",
    "K=5\n",
    "def oof_preds(best_model):\n",
    "\n",
    "    # make KFold\n",
    "    folds = StratifiedKFold(n_splits=K, random_state=61, shuffle=True)\n",
    "    final_preds = []\n",
    "    losses = []\n",
    "    oof = np.full(len(X), np.nan)\n",
    "    # fitting with best_model\n",
    "    for i, (train_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "        X_train = X.iloc[train_idx, :]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        X_val = X.iloc[val_idx, :]\n",
    "        y_val = y.iloc[val_idx]\n",
    "\n",
    "        print(f\"========== Fold {i+1} ==========\")\n",
    "        best_model.fit(X_train, y_train)\n",
    "        preds = best_model.predict_proba(X_val)[:, 1]\n",
    "        oof[val_idx] = preds\n",
    "        test_preds = best_model.predict_proba(test_df)[:, 1]\n",
    "        final_preds.append(test_preds)\n",
    "        loss = roc_auc_score(y_val, preds)\n",
    "\n",
    "        losses.append(loss)\n",
    "\n",
    "    avg_loss = np.mean(losses)\n",
    "    print(f\"Loss : {avg_loss:.4f}\")\n",
    "    return final_preds, oof, avg_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Fold 1 ==========\n",
      "========== Fold 2 ==========\n",
      "========== Fold 3 ==========\n",
      "========== Fold 4 ==========\n",
      "========== Fold 5 ==========\n",
      "Loss : 0.7879\n",
      "========== Fold 1 ==========\n",
      "========== Fold 2 ==========\n",
      "========== Fold 3 ==========\n",
      "========== Fold 4 ==========\n",
      "========== Fold 5 ==========\n",
      "Loss : 0.7897\n",
      "========== Fold 1 ==========\n",
      "========== Fold 2 ==========\n",
      "========== Fold 3 ==========\n",
      "========== Fold 4 ==========\n",
      "========== Fold 5 ==========\n",
      "Loss : 0.7912\n",
      "========== Fold 1 ==========\n",
      "========== Fold 2 ==========\n",
      "========== Fold 3 ==========\n",
      "========== Fold 4 ==========\n",
      "========== Fold 5 ==========\n",
      "Loss : 0.7910\n",
      "========== Fold 1 ==========\n",
      "========== Fold 2 ==========\n",
      "========== Fold 3 ==========\n",
      "========== Fold 4 ==========\n",
      "========== Fold 5 ==========\n",
      "Loss : 0.7913\n",
      "========== Fold 1 ==========\n",
      "========== Fold 2 ==========\n",
      "========== Fold 3 ==========\n",
      "========== Fold 4 ==========\n",
      "========== Fold 5 ==========\n",
      "Loss : 0.7875\n",
      "========== Fold 1 ==========\n",
      "========== Fold 2 ==========\n",
      "========== Fold 3 ==========\n",
      "========== Fold 4 ==========\n",
      "========== Fold 5 ==========\n",
      "Loss : 0.7913\n",
      "========== Fold 1 ==========\n",
      "========== Fold 2 ==========\n",
      "========== Fold 3 ==========\n",
      "========== Fold 4 ==========\n",
      "========== Fold 5 ==========\n",
      "Loss : 0.7916\n",
      "========== Fold 1 ==========\n",
      "========== Fold 2 ==========\n",
      "========== Fold 3 ==========\n",
      "========== Fold 4 ==========\n",
      "========== Fold 5 ==========\n",
      "Loss : 0.7920\n"
     ]
    }
   ],
   "source": [
    "model_scores = [(model_name, oof_preds(model)[2]) for model_name, model in models]\n",
    "model_scores.sort(key=lambda m: m[1], reverse=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "[('lightgbm', 0.7920163420770895),\n ('xgboost', 0.7916494425928904),\n ('rf', 0.791317471130813),\n ('hgb', 0.791295894674041),\n ('logistic_nystroem', 0.7911558772672646),\n ('extra', 0.7910446684288237),\n ('logistic', 0.7896575091156404),\n ('linear', 0.7879088097006365),\n ('knn', 0.7875235235646615)]"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Fold 1 ==========\n",
      "========== Fold 2 ==========\n",
      "========== Fold 3 ==========\n",
      "========== Fold 4 ==========\n",
      "========== Fold 5 ==========\n",
      "Loss : 0.7922\n",
      "========== Fold 1 ==========\n",
      "========== Fold 2 ==========\n",
      "========== Fold 3 ==========\n",
      "========== Fold 4 ==========\n",
      "========== Fold 5 ==========\n",
      "Loss : 0.7924\n",
      "========== Fold 1 ==========\n",
      "========== Fold 2 ==========\n",
      "========== Fold 3 ==========\n",
      "========== Fold 4 ==========\n",
      "========== Fold 5 ==========\n",
      "Loss : 0.7924\n",
      "========== Fold 1 ==========\n",
      "========== Fold 2 ==========\n",
      "========== Fold 3 ==========\n",
      "========== Fold 4 ==========\n",
      "========== Fold 5 ==========\n",
      "Loss : 0.7926\n",
      "========== Fold 1 ==========\n",
      "========== Fold 2 ==========\n",
      "========== Fold 3 ==========\n",
      "========== Fold 4 ==========\n",
      "========== Fold 5 ==========\n",
      "Loss : 0.7926\n",
      "best model 개술 : 5, best oof score : 0.7925872440398897\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "selected_models = [\n",
    "    ('lightgbm',LGBMClassifier(\n",
    "            max_depth=24,\n",
    "            num_leaves=32,\n",
    "            min_child_samples=74,\n",
    "            colsample_bytree=0.7080352104708246,\n",
    "            n_estimators=63,\n",
    "            learning_rate=0.09089244698723227,\n",
    "            random_state=61\n",
    "        )\n",
    "    ),\n",
    "    ('xgboost',XGBClassifier(\n",
    "            max_depth=5,\n",
    "            colsample_bynode=0.6028784042231218,\n",
    "            reg_lambda=1.9107959408881667,\n",
    "            n_estimators=38,\n",
    "            learning_rate=0.19089614460186538,\n",
    "            random_state=61,\n",
    "            eval_metric=roc_auc_score,\n",
    "        )\n",
    "    ),\n",
    "    ('rf',RandomForestClassifier(min_samples_leaf=220, max_features=1.0, random_state=61)),\n",
    "    ('hgb', HistGradientBoostingClassifier(random_state=61)),\n",
    "    ('logistic_nystroem',make_pipeline(\n",
    "        FunctionTransformer(np.log1p),\n",
    "        Nystroem(n_components=400, random_state=61),\n",
    "        StandardScaler(),\n",
    "        LogisticRegression(dual=False, C=0.0032, max_iter=1500, random_state=61)\n",
    "    )),\n",
    "    ('extra', ExtraTreesClassifier(\n",
    "            n_estimators=100,\n",
    "            min_samples_leaf=110,\n",
    "            max_features=1.0,\n",
    "            random_state=61\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "best_preds = None\n",
    "best_score = 0\n",
    "best_model_num = 0\n",
    "for model_num in range(2, 7):\n",
    "    weights = [6,5,4,3,2,1]\n",
    "    voter_model = VotingClassifier(selected_models[:model_num], weights = weights[:model_num], voting = 'soft')\n",
    "    preds, oof, oof_score = oof_preds(voter_model)\n",
    "    preds = np.mean(preds, axis=0)\n",
    "    if model_num==2 or best_score<oof_score:\n",
    "        best_preds = preds\n",
    "        best_score = oof_score\n",
    "        best_model_num = model_num\n",
    "print(f'best model 개수 : {best_model_num}, best oof score : {best_score}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "submission_df['defects'] = best_preds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "submission_df.to_csv(data_path+'submission/ensemble_selected_grid.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}