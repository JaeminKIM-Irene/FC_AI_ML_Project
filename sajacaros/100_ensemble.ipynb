{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "data_path='../data/'\n",
    "ambrosm_oof_df = pd.read_csv(data_path+'oof/ambrosm.csv')\n",
    "lightgbm_oof_df = pd.read_csv(data_path+'oof/lightgbm.csv')\n",
    "xgboost_oof_df = pd.read_csv(data_path+'oof/xgboost.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(data_path+'train.csv', index_col='id')\n",
    "test_df = pd.read_csv(data_path+'test.csv', index_col='id')\n",
    "submission_df = pd.read_csv(data_path+'sample_submission.csv', index_col='id')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "X = train_df.drop(columns='defects')\n",
    "y = train_df['defects']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['linear_best_oof', 'logistic_best_oof', 'logistic_nystroem_best_oof',\n       'extra_best_oof', 'rf_best_oof', 'knn_best_oof', 'hgb_best_oof',\n       'xgboost_oof', 'lightgbm_oof'],\n      dtype='object')"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_oof_df = pd.concat([ambrosm_oof_df, xgboost_oof_df, lightgbm_oof_df], axis=1)\n",
    "all_oof_df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0.15431888, -0.25536847,  0.3372877 ,  0.0925106 ,  0.60583746,\n        0.00545892,  0.12015779,  0.30886997,  0.47717188])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "weights = RidgeClassifier(random_state = 61).fit(all_oof_df, train_df.defects).coef_[0]\n",
    "weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import FunctionTransformer, PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "models = [\n",
    "    ('linear',make_pipeline(\n",
    "                FunctionTransformer(np.log1p),\n",
    "                PolynomialFeatures(2, include_bias=False),\n",
    "                StandardScaler(),\n",
    "                CalibratedClassifierCV(LinearSVC(dual=False, C=0.78858))\n",
    "            )),\n",
    "    ('logistic',make_pipeline(\n",
    "                FunctionTransformer(np.log1p),\n",
    "                PolynomialFeatures(2, include_bias=False),\n",
    "                StandardScaler(),\n",
    "                LogisticRegression(\n",
    "                    dual=False,\n",
    "                    C=0.32,\n",
    "                    class_weight='balanced',\n",
    "                    max_iter=1500,\n",
    "                    random_state=61,\n",
    "                    solver='newton-cholesky'\n",
    "                )\n",
    "            )),\n",
    "    ('logistic_nystroem',make_pipeline(\n",
    "                FunctionTransformer(np.log1p),\n",
    "                Nystroem(n_components=400, random_state=61),\n",
    "                StandardScaler(),\n",
    "                LogisticRegression(dual=False, C=0.0032, max_iter=1500, random_state=61)\n",
    "            )),\n",
    "    ('extra',make_pipeline(\n",
    "                FunctionTransformer(np.log1p),\n",
    "                ExtraTreesClassifier(\n",
    "                    n_estimators=100,\n",
    "                    min_samples_leaf=110,\n",
    "                    max_features=1.0,\n",
    "                    random_state=61\n",
    "                ),\n",
    "            )),\n",
    "    ('rf',RandomForestClassifier(min_samples_leaf=220, max_features=1.0, random_state=61)),\n",
    "    ('knn',make_pipeline(\n",
    "                FunctionTransformer(np.log1p),\n",
    "                StandardScaler(),\n",
    "                KNeighborsClassifier(\n",
    "                    n_neighbors=360,\n",
    "                    weights='distance'\n",
    "                )\n",
    "            )),\n",
    "    ('hgb',HistGradientBoostingClassifier(random_state=61)),\n",
    "    ('xgboost',XGBClassifier(\n",
    "            max_depth=5,\n",
    "            colsample_bynode=0.5893033001541113,\n",
    "            reg_lambda=2.51229884910896,\n",
    "            n_estimators=77,\n",
    "            learning_rate=0.11576587720138976,\n",
    "            random_state=61,\n",
    "            eval_metric=roc_auc_score,\n",
    "        )\n",
    "    ),\n",
    "    ('lightgbm',LGBMClassifier(\n",
    "            max_depth=20,\n",
    "            num_leaves=128,\n",
    "            min_child_samples=63,\n",
    "            colsample_bytree=0.6674419461546907,\n",
    "            n_estimators=966,\n",
    "            learning_rate=0.008527944132064239,\n",
    "            random_state=61\n",
    "        )\n",
    "    ),\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "# Make KFold OOF prediction\n",
    "K=5\n",
    "def oof_preds(best_model):\n",
    "\n",
    "    # make KFold\n",
    "    folds = StratifiedKFold(n_splits=K, random_state=61, shuffle=True)\n",
    "    final_preds = []\n",
    "    losses = []\n",
    "    oof = np.full(len(X), np.nan)\n",
    "    # fitting with best_model\n",
    "    for i, (train_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "        X_train = X.iloc[train_idx, :]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        X_val = X.iloc[val_idx, :]\n",
    "        y_val = y.iloc[val_idx]\n",
    "\n",
    "        print(f\"========== Fold {i+1} ==========\")\n",
    "        best_model.fit(X_train, y_train)\n",
    "        preds = best_model.predict_proba(X_val)[:, 1]\n",
    "        oof[val_idx] = preds\n",
    "        test_preds = best_model.predict_proba(test_df)[:, 1]\n",
    "        final_preds.append(test_preds)\n",
    "        loss = roc_auc_score(y_val, preds)\n",
    "\n",
    "        losses.append(loss)\n",
    "\n",
    "    avg_loss = np.mean(losses)\n",
    "    print(f\"Loss : {avg_loss:.4f}\")\n",
    "    return final_preds, oof"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Fold 1 ==========\n",
      "========== Fold 2 ==========\n",
      "========== Fold 3 ==========\n",
      "========== Fold 4 ==========\n",
      "========== Fold 5 ==========\n",
      "Loss : 0.7923\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([0.18962561, 0.16190545, 0.64299568, ..., 0.14131224, 0.07410677,\n       0.77610477])"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voter_model = VotingClassifier(models, weights = weights, voting = 'soft')\n",
    "\n",
    "preds, oof = oof_preds(voter_model)\n",
    "preds = np.mean(preds, axis=0)\n",
    "preds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "submission_df['defects'] = preds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "submission_df.to_csv(data_path+'submission_final.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}